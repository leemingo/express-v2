{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6be2b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "import torch\n",
    "\n",
    "from datasets import PressingSequenceDataset, SoccerMapInputDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "num_features = train_dataset[0]['features'].shape[2]\n",
    "\n",
    "# ê° í”¼ì²˜ ì°¨ì›ë³„ ìµœì†Ÿê°’ê³¼ ìµœëŒ“ê°’ì„ ì €ìž¥í•  í…ì„œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "# shape: [NumFeatures]\n",
    "current_min_vals = torch.full((num_features,), float('inf'), dtype=torch.float32)\n",
    "current_max_vals = torch.full((num_features,), float('-inf'), dtype=torch.float32)\n",
    "\n",
    "for idx in range(len(train_dataset)):\n",
    "    features_tensor = train_dataset[0]['features']\n",
    "    min_in_tensor = torch.min(torch.min(features_tensor, dim=0).values, dim=0).values\n",
    "    max_in_tensor = torch.max(torch.max(features_tensor, dim=0).values, dim=0).values\n",
    "\n",
    "    current_min_vals = torch.minimum(current_min_vals, min_in_tensor)\n",
    "    current_max_vals = torch.maximum(current_max_vals, max_in_tensor)\n",
    "\n",
    "self.feature_min_vals = current_min_vals\n",
    "self.feature_max_vals = current_max_vals\n",
    "\n",
    "# __getitem__ì—ì„œ ë¸Œë¡œë“œìºìŠ¤íŒ…ì„ ìœ„í•´ shape ë³€ê²½: [1, 1, NumFeatures]\n",
    "self.min_vals_bcast = self.feature_min_vals.reshape(1, 1, -1)\n",
    "self.max_vals_bcast = self.feature_max_vals.reshape(1, 1, -1)\n",
    "\n",
    "self.feature_ranges = self.max_vals_bcast - self.min_vals_bcast\n",
    "# ë²”ìœ„ê°€ 0ì¸ ê²½ìš° (í”¼ì²˜ ê°’ì´ ìƒìˆ˜ì¸ ê²½ìš°) 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.\n",
    "# ì´ ê²½ìš° ì •ê·œí™”ëœ ê°’ì€ 0ì´ ë©ë‹ˆë‹¤. ( (X - min) / 1 = 0 )\n",
    "self.feature_ranges[self.feature_ranges == 0] = 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44ac95b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14241, 1721)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/data/MHL/pressing-intensity\"\n",
    "\n",
    "with open(f\"{data_path}/train_dataset.pkl\", \"rb\") as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "with open(f\"{data_path}/test_dataset.pkl\", \"rb\") as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff0d100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'pressing_intensity', 'label', 'presser_id', 'agent_order'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df18d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features : torch.Size([150, 23, 8])\n",
      "Pressing Intensity : torch.Size([150, 11, 11])\n",
      "Labels : 0\n",
      "Presser ID : 77414\n",
      "Players Order : ['188178', '250079', '250101', '250102', '500133', '500140', '500141', '500142', '62365', '62386', '77414', '187259', '343587', '408792', '500113', '500115', '500116', '500117', '500118', '500121', '500502', '83615', 'ball']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features : {sample['features'].shape}\")\n",
    "print(f\"Pressing Intensity : {sample['pressing_intensity'].shape}\")\n",
    "print(f\"Labels : {sample['label']}\")\n",
    "print(f\"Presser ID : {sample['presser_id']}\")\n",
    "print(f\"Players Order : {sample['agent_order']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5fbfc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([150, 23, 8]), torch.Size([150, 11, 11]), tensor(0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = sample['features']\n",
    "press_intensity = sample['pressing_intensity']\n",
    "y_tensor = sample['label']\n",
    "x_tensor.shape, press_intensity.shape, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03cccea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : -58.351173400878906 ~ 57.75\n",
      "y : -38.8927001953125 ~ 38.8927001953125\n",
      "vx : -342.4437561035156 ~ 301.3289489746094\n",
      "vy : -200.180419921875 ~ 280.8352966308594\n",
      "v : 0.0 ~ 28.0\n",
      "ax : -11283.9609375 ~ 9192.126953125\n",
      "ay : -5758.1103515625 ~ 8190.6416015625\n",
      "a : 0.0 ~ 13.5\n"
     ]
    }
   ],
   "source": [
    "x_tensor_lst = [sample['features'] for sample in train_dataset]\n",
    "x_tensor_lst = torch.cat(x_tensor_lst)\n",
    "feature_cols = ['x', 'y', 'vx', 'vy', 'v', 'ax', 'ay', 'a']\n",
    "\n",
    "for i in range(8):\n",
    "    print(f\"{feature_cols[i]} : {x_tensor_lst[..., i].min()} ~ {x_tensor_lst[..., i].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bc7c6",
   "metadata": {},
   "source": [
    "# 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff7bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seq = 150\n",
    "num_agents = 11\n",
    "use_pressing_intensity = False\n",
    "selected_features_idx = [1, 2, 4, 7]\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "for i in range(len(train_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-90:]\n",
    "    press_intensity = sample['pressing_intensity'][-90:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "            \n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    train_features.append(feature_vector)\n",
    "    train_labels.append(y_tensor.item())\n",
    "\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "for i in range(len(test_dataset)):\n",
    "    sample = test_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-90:]\n",
    "    press_intensity = sample['pressing_intensity'][-90:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    \n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    test_features.append(feature_vector)\n",
    "    test_labels.append(y_tensor.item())\n",
    "\n",
    "X_train = np.array(train_features)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = np.array(test_features)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b82432f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Dataset Distribution Summary\n",
      "========================================\n",
      "Train Set:\n",
      "  Total samples: 11392\n",
      "    Label 0:  9138 samples (80.21%)\n",
      "    Label 1:  2254 samples (19.79%)\n",
      "----------------------------------------\n",
      "Validation Set:\n",
      "  Total samples: 2849\n",
      "    Label 0:  2281 samples (80.06%)\n",
      "    Label 1:   568 samples (19.94%)\n",
      "----------------------------------------\n",
      "Test Set:\n",
      "  Total samples: 1721\n",
      "    Label 0:  1358 samples (78.91%)\n",
      "    Label 1:   363 samples (21.09%)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_dataset_distribution(y_train, y_val, y_test):\n",
    "    def _print_split(name, labels):\n",
    "        total = len(labels)\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        print(f\"{name} Set:\")\n",
    "        print(f\"  Total samples: {total}\")\n",
    "        for label, count in zip(unique, counts):\n",
    "            percent = (count / total) * 100\n",
    "            print(f\"    Label {label}: {count:>5} samples ({percent:5.2f}%)\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    print(\"\\nðŸ“Š Dataset Distribution Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    _print_split(\"Train\", y_train)\n",
    "    _print_split(\"Validation\", y_val)\n",
    "    _print_split(\"Test\", y_test)\n",
    "\n",
    "print_dataset_distribution(y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e48d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost DMatrix objects for train and test sets\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Set XGBoost training parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # binary classification\n",
    "    'eval_metric': 'auc',            # evaluation metric: AUC\n",
    "    'max_depth': 6,                  # maximum depth of trees\n",
    "    'eta': 0.1,                      # learning rate\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Specify the watchlist to evaluate performance on training and test sets during training\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "856ef086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/miniconda/envs/mhl_py311/lib/python3.11/site-packages/xgboost/core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.72404\teval-auc:0.59755\n",
      "[1]\ttrain-auc:0.77449\teval-auc:0.61684\n",
      "[2]\ttrain-auc:0.80143\teval-auc:0.61842\n",
      "[3]\ttrain-auc:0.82563\teval-auc:0.62081\n",
      "[4]\ttrain-auc:0.83993\teval-auc:0.62739\n",
      "[5]\ttrain-auc:0.85611\teval-auc:0.63009\n",
      "[6]\ttrain-auc:0.86313\teval-auc:0.63397\n",
      "[7]\ttrain-auc:0.87409\teval-auc:0.63416\n",
      "[8]\ttrain-auc:0.88935\teval-auc:0.63792\n",
      "[9]\ttrain-auc:0.89944\teval-auc:0.63648\n",
      "[10]\ttrain-auc:0.90767\teval-auc:0.63826\n",
      "[11]\ttrain-auc:0.91626\teval-auc:0.63678\n",
      "[12]\ttrain-auc:0.92196\teval-auc:0.63293\n",
      "[13]\ttrain-auc:0.92891\teval-auc:0.63344\n",
      "[14]\ttrain-auc:0.93481\teval-auc:0.63360\n",
      "[15]\ttrain-auc:0.93753\teval-auc:0.63349\n",
      "[16]\ttrain-auc:0.94254\teval-auc:0.63322\n",
      "[17]\ttrain-auc:0.94739\teval-auc:0.63347\n",
      "[18]\ttrain-auc:0.94938\teval-auc:0.63573\n",
      "[19]\ttrain-auc:0.95371\teval-auc:0.63360\n",
      "[20]\ttrain-auc:0.95596\teval-auc:0.63550\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost model with early stopping on the evaluation set\n",
    "bst = xgb.train(params, dtrain, num_rounds, watchlist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96af079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8027\n",
      "Test AUC: 0.6491\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c5df0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7989\n",
      "Test AUC: 0.6465\n"
     ]
    }
   ],
   "source": [
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb1665e",
   "metadata": {},
   "source": [
    "# 2. SoccerMap / exPress Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96d976f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import os\n",
    "os.chdir('/home/work/MHL/express-v2')\n",
    "import argparse # To accept checkpoint path as argument\n",
    "\n",
    "# Import project modules\n",
    "# import config  # Import static configurations\n",
    "from model import PytorchSoccerMapModel # Import Lightning model\n",
    "from datasets import PressingSequenceDataset, SoccerMapInputDataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08a1fab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from /data/MHL/pressing-intensity/test_dataset.pkl...\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42, workers=True) # Ensure reproducibility\n",
    "\n",
    "DATA_PATH = \"/data/MHL/pressing-intensity\" # Path where pickled datasets are saved\n",
    "test_dataset = SoccerMapInputDataset(os.path.join(DATA_PATH, \"test_dataset.pkl\"))\n",
    "\n",
    "if len(test_dataset) == 0:\n",
    "    print(\"Loaded test dataset is empty. Exiting.\")\n",
    "\n",
    "# Custom collate function to handle potential None values from dataset errors\n",
    "def collate_fn_skip_none(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    if not batch: return None\n",
    "    try: return torch.utils.data.dataloader.default_collate(batch)\n",
    "    except RuntimeError: return None # Skip batch if collation error\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    # collate_fn=collate_fn_skip_none\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45aabfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Train a pressing evaluation model.\")\n",
    "# parser.add_argument(\"--model_type\", type=str, default=\"soccermap\", choices=['soccermap', 'xgboost', 'exPress'], help=\"Path to the model checkpoint (.ckpt) file saved during training.\")\n",
    "# parser.add_argument(\"--root_path\", type=str, default=\"/data/MHL/pressing-intensity\", help=\"Path to the data file.\")\n",
    "parser.add_argument(\"--model_type\", type=str, default=\"soccermap\", choices=['soccermap', 'xgboost', 'exPress'], help=\"Path to the model checkpoint (.ckpt) file saved during training.\")\n",
    "parser.add_argument(\"--root_path\", type=str, default=\"/data/MHL/pressing-intensity\", help=\"Path to the data file.\")\n",
    "parser.add_argument(\"--mode\", type=str, default=\"train\", choices=['train', 'test'], help=\"Mode: 'train' or 'test'.\")\n",
    "parser.add_argument(\"--ckpt_path\", type=str, default=None, help=\"Path to checkpoint file (Required for 'test' mode).\")\n",
    "parser.add_argument(\"--params_path\", type=str, default=\"params.json\", help=\"Path to the JSON containing configurations.\")\n",
    "parser.add_argument(\"--seed\", type=int, default=42, help=\"Seed number.\")\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "args.mode = 'test'\n",
    "args.model_type = \"exPress\"\n",
    "args.ckpt_path = \"/data/MHL/pressing-intensity/checkpoints/exPress-epoch=28-val_loss=0.49.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4dcd43e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations loaded from params.json.\n"
     ]
    }
   ],
   "source": [
    "from components import press\n",
    "\n",
    "\n",
    "component_dict = {\n",
    "                    \"soccermap\": press.SoccerMapComponent,\n",
    "                    \"exPress\": press.exPressComponent,\n",
    "                }\n",
    "\n",
    "exp = component_dict[args.model_type](args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193af97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhl_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
