{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be2b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 17:50:57.216066: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-14 17:50:57.216113: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-14 17:50:57.216145: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-14 17:50:57.224359: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-14 17:50:57.988563: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/exPress/express-v2\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import PressingSequenceDataset, SoccerMapInputDataset\n",
    "import config as C\n",
    "import features as F\n",
    "from bisect import bisect_right\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31019cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6569, 598, 637)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/home/exPress/express-v2/data/bepro/pressing_intensity\"\n",
    "\n",
    "with open(f\"{data_path}/train_dataset.pkl\", \"rb\") as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "with open(f\"{data_path}/valid_dataset.pkl\", \"rb\") as f:\n",
    "    valid_dataset = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(f\"{data_path}/test_dataset.pkl\", \"rb\") as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0669211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Game IDs: (30, ['126293', '126298', '126306', '126309', '126315', '126325', '126332', '126341', '126348', '126350', '126356', '126364', '126367', '126378', '126380', '126386', '126391', '126401', '126408', '126411', '126418', '126424', '126429', '126433', '126444', '126448', '126455', '126458', '126466', '126473'])\n",
      "Valid Game IDs: (3, ['126476', '153364', '153373'])\n",
      "Test Game IDs: (3, ['153379', '153385', '153387'])\n"
     ]
    }
   ],
   "source": [
    "def check_game_ids(dataset):\n",
    "    game_ids = set()\n",
    "    for idx, sample in enumerate(dataset):\n",
    "        game_id, _, _ = sample['match_info'].split('-')\n",
    "        game_ids.add(game_id)\n",
    "    return len(game_ids), sorted(game_ids)\n",
    "\n",
    "print(\"Train Game IDs:\", check_game_ids(train_dataset))\n",
    "print(\"Valid Game IDs:\", check_game_ids(valid_dataset))\n",
    "print(\"Test Game IDs:\", check_game_ids(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4423e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_dataset[0]\n",
    "\n",
    "print(f\"Features : {sample['features'].shape}\")\n",
    "print(f\"Pressing Intensity : {sample['pressing_intensity'].shape}\")\n",
    "print(f\"Labels : {sample['label']}\")\n",
    "print(f\"Presser ID : {sample['presser_id']}\")\n",
    "print(f\"Players Order : {sample['agent_order']}\")\n",
    "print(f\"match info : {sample['match_info']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ce2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def transform_feature_dict(feature_dict):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ feature_dictì˜ ê°’ì„ [0, 1] ë²”ìœ„ë¡œ Min-Max ìŠ¤ì¼€ì¼ë§í•©ë‹ˆë‹¤.\n",
    "    ê²°ì¸¡ì¹˜(NaN)ëŠ” ë³€í™˜ ê³¼ì •ì—ì„œ ì œì™¸ë˜ë©°, ìµœì¢…ì ìœ¼ë¡œëŠ” 0.0ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    vals = [v for v in feature_dict.values() if pd.notna(v)]\n",
    "    \n",
    "    if not vals: # ê°’ì´ ì—†ê±°ë‚˜ ëª¨ë‘ NaNì¸ ê²½ìš°\n",
    "        return {k: 0.0 if pd.isna(v) else v for k, v in feature_dict.items()} # ëª¨ë“  NaNì„ 0.0ìœ¼ë¡œ, ê·¸ ì™¸ëŠ” ê·¸ëŒ€ë¡œ ë‘ \n",
    "\n",
    "    min_val = min(vals)\n",
    "    max_val = max(vals)\n",
    "    \n",
    "    # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì˜¤ë¥˜ ë°©ì§€: max_valê³¼ min_valì´ ê°™ìœ¼ë©´ (ëª¨ë“  ìœ íš¨í•œ ê°’ì´ ë™ì¼í•˜ë©´) 1.0ìœ¼ë¡œ ë‚˜ëˆ”\n",
    "    range_val = max_val - min_val if max_val != min_val else 1.0 \n",
    "    \n",
    "    transformed_dict = {}\n",
    "    for k, v in feature_dict.items():\n",
    "        if pd.notna(v):\n",
    "            transformed_dict[k] = (v - min_val) / range_val\n",
    "        else:\n",
    "            transformed_dict[k] = 0.0 # NaN ê°’ì€ 0.0ìœ¼ë¡œ ì²˜ë¦¬\n",
    "    return transformed_dict\n",
    "\n",
    "def update_features(dataset, feature_list, processed_data_path, transform = True, cache_dir=\"feature_cache\"):\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    game_sample_map = defaultdict(list)\n",
    "\n",
    "    # 1. game_id ê¸°ì¤€ìœ¼ë¡œ ìƒ˜í”Œ ì¸ë±ìŠ¤ì™€ frame_idë¥¼ ëª¨ìŒ\n",
    "    for idx, sample in enumerate(dataset): # dataset.__len__ì— ì˜í•´ ê²°ì •ë˜ëŠ” ê¸¸ì´ë§Œí¼ ë£¨í”„\n",
    "        game_id, period_id_str, frame_id_str = sample['match_info'].split('-')\n",
    "        frame_id = int(frame_id_str)\n",
    "        period_id = int(float(period_id_str))\n",
    "        game_sample_map[game_id].append((idx, period_id, frame_id))\n",
    "\n",
    "\n",
    "    # 2. game_id ë‹¨ìœ„ë¡œ ëª¨ë“  ì²˜ë¦¬ (ë°ì´í„° ë¡œë“œ, timestamp ë§¤í•‘, í”¼ì²˜ ê³„ì‚°, ë°ì´í„°ì…‹ ì—…ë°ì´íŠ¸)\n",
    "    for game_id, frame_infos_for_game in game_sample_map.items():\n",
    "        game_feature_dir = os.path.join(cache_dir, game_id)\n",
    "        os.makedirs(game_feature_dir, exist_ok=True)\n",
    "        print(f\"\\n--- Processing Game ID: {game_id} ---\")\n",
    "\n",
    "        tracking_df = pd.read_csv(os.path.join(processed_data_path, game_id, f\"{game_id}_traces.csv\"))\n",
    "        events_df = pd.read_csv(os.path.join(processed_data_path, game_id, f\"{game_id}_merged.csv\"))\n",
    "        teams_df = pd.read_csv(os.path.join(processed_data_path, game_id, f\"{game_id}_teams.csv\"))\n",
    "        events_df[\"time_seconds\"] = pd.to_numeric(events_df[\"time_seconds\"], errors=\"coerce\")\n",
    "\n",
    "        # 2-1. frame_id -> timestamp ë§¤í•‘ (ìŠ¤ì½”í”„ê°€ ì´ ë£¨í”„ ë‚´ë¶€ë¡œ ì œí•œë¨)\n",
    "        frame_id_to_ts = tracking_df.set_index(['period_id', 'frame_id'])['time_seconds'].to_dict() \n",
    "\n",
    "        precomputed_game_features = {} \n",
    "        # 2-2. ì¼ë‹¨ ì „ì²´ì— ëŒ€í•´ ê³„ì‚° ì§„í–‰\n",
    "        for feature_name in feature_list: # ê° í”¼ì²˜ ì´ë¦„ì— ëŒ€í•´\n",
    "            feature_cache_path = os.path.join(game_feature_dir, f\"{feature_name}.pkl\")\n",
    "            if os.path.exists(feature_cache_path):\n",
    "                with open(feature_cache_path, 'rb') as f:\n",
    "                    feat_result_df = pickle.load(f)\n",
    "            else:\n",
    "                func = getattr(F, feature_name)\n",
    "                game_feature_dir = os.path.join(cache_dir, game_id)\n",
    "                os.makedirs(game_feature_dir, exist_ok=True)\n",
    "                if feature_name == \"sum_pitch_control\":\n",
    "                    feat_result_df  = func(events_df, teams_df)                              \n",
    "                else:\n",
    "                    feat_result_df = func(events_df)  # Series with index=action_id\n",
    "                with open(feature_cache_path, 'wb') as f:\n",
    "                    pickle.dump(feat_result_df, f)\n",
    "            raw_dict = feat_result_df.set_index('action_id')[feature_name].to_dict() \n",
    "            \n",
    "            if transform:\n",
    "                precomputed_game_features[feature_name] = transform_feature_dict(raw_dict)\n",
    "            else:\n",
    "                precomputed_game_features[feature_name] = raw_dict\n",
    "                \n",
    "        # 2-3. ìƒ˜í”Œë³„ ê³¼ê±° ì´ë²¤íŠ¸ Bê°œì— ëŒ€í•´ feature ì¶”ì¶œ\n",
    "        for sample_idx, period_id, fid in frame_infos_for_game: \n",
    "            ts = frame_id_to_ts.get((period_id, fid)) \n",
    "            current_sample_data_dict = dataset[sample_idx] \n",
    "            original_feature_tensor = current_sample_data_dict['features'] \n",
    "            B, N, D = original_feature_tensor.shape # BëŠ” ì´ ìƒ˜í”Œì˜ ê³¼ê±° ì´ë²¤íŠ¸ ìˆ˜ (context_length)\n",
    "            past_events = events_df[events_df[\"time_seconds\"] < ts].head(B)\n",
    "            event_ids = past_events[\"action_id\"].tolist()\n",
    "\n",
    "            # ê° featureë³„ë¡œ (B, 1) í…ì„œë¥¼ ìƒì„±í•˜ê³  í•©ì¹˜ê¸°\n",
    "            new_feature_list = []\n",
    "            for feature_name in feature_list:\n",
    "                feat_dict = precomputed_game_features[feature_name]\n",
    "                feat_vals = [feat_dict.get(eid, np.nan) for eid in event_ids]  # (B,)\n",
    "                feat_tensor = torch.tensor(feat_vals, dtype=torch.float32).view(B, 1)  # (B, 1)\n",
    "                expanded = feat_tensor.unsqueeze(1).expand(-1, N, -1)  # (B, N, 1)\n",
    "                new_feature_list.append(expanded)\n",
    "\n",
    "            # ëª¨ë“  feature í†µí•©\n",
    "            new_concat = torch.cat(new_feature_list, dim=-1)  # (B, N, F')\n",
    "            final_feature_tensor = torch.cat([original_feature_tensor, new_concat], dim=-1)\n",
    "            current_sample_data_dict['features'] = final_feature_tensor\n",
    "            dataset[sample_idx] = current_sample_data_dict  # ìµœì¢… ì €ì¥\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cd98db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_dataset (before)] Feature shape before update:\n",
      "  Sample 0: torch.Size([2, 23, 18])\n",
      "  Sample 1: torch.Size([1, 23, 18])\n",
      "  Sample 2: torch.Size([1, 23, 18])\n",
      "[test_dataset (before)] Feature shape before update:\n",
      "  Sample 0: torch.Size([4, 23, 18])\n",
      "  Sample 1: torch.Size([4, 23, 18])\n",
      "  Sample 2: torch.Size([2, 23, 18])\n"
     ]
    }
   ],
   "source": [
    "def print_feature_shape_diff(dataset, dataset_name=\"dataset\"):\n",
    "    print(f\"[{dataset_name}] Feature shape before update:\")\n",
    "    for i in range(3):  # ì•ì˜ 3ê°œ ìƒ˜í”Œë§Œ ì˜ˆì‹œë¡œ í™•ì¸\n",
    "        print(f\"  Sample {i}: {dataset[i]['features'].shape}\")\n",
    "\n",
    "# 1. ì—…ë°ì´íŠ¸ ì „\n",
    "print_feature_shape_diff(train_dataset, \"train_dataset (before)\")\n",
    "print_feature_shape_diff(test_dataset, \"test_dataset (before)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134fceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Game ID: 126293 ---\n",
      "\n",
      "--- Processing Game ID: 126298 ---\n",
      "\n",
      "--- Processing Game ID: 126306 ---\n",
      "\n",
      "--- Processing Game ID: 126309 ---\n",
      "\n",
      "--- Processing Game ID: 126315 ---\n",
      "\n",
      "--- Processing Game ID: 126325 ---\n",
      "\n",
      "--- Processing Game ID: 126332 ---\n",
      "\n",
      "--- Processing Game ID: 126341 ---\n",
      "\n",
      "--- Processing Game ID: 126348 ---\n",
      "\n",
      "--- Processing Game ID: 126350 ---\n",
      "\n",
      "--- Processing Game ID: 126356 ---\n",
      "\n",
      "--- Processing Game ID: 126364 ---\n",
      "\n",
      "--- Processing Game ID: 126367 ---\n",
      "\n",
      "--- Processing Game ID: 126378 ---\n",
      "\n",
      "--- Processing Game ID: 126380 ---\n",
      "\n",
      "--- Processing Game ID: 126386 ---\n",
      "\n",
      "--- Processing Game ID: 126391 ---\n",
      "\n",
      "--- Processing Game ID: 126401 ---\n",
      "\n",
      "--- Processing Game ID: 126408 ---\n",
      "\n",
      "--- Processing Game ID: 126411 ---\n",
      "\n",
      "--- Processing Game ID: 126418 ---\n",
      "\n",
      "--- Processing Game ID: 126424 ---\n",
      "\n",
      "--- Processing Game ID: 126429 ---\n",
      "\n",
      "--- Processing Game ID: 126433 ---\n",
      "\n",
      "--- Processing Game ID: 126444 ---\n",
      "\n",
      "--- Processing Game ID: 126448 ---\n",
      "\n",
      "--- Processing Game ID: 126455 ---\n",
      "\n",
      "--- Processing Game ID: 126458 ---\n",
      "\n",
      "--- Processing Game ID: 126466 ---\n",
      "\n",
      "--- Processing Game ID: 126473 ---\n",
      "\n",
      "--- Processing Game ID: 126476 ---\n",
      "\n",
      "--- Processing Game ID: 153364 ---\n",
      "\n",
      "--- Processing Game ID: 153373 ---\n",
      "\n",
      "--- Processing Game ID: 153379 ---\n",
      "\n",
      "--- Processing Game ID: 153385 ---\n",
      "\n",
      "--- Processing Game ID: 153387 ---\n"
     ]
    }
   ],
   "source": [
    "processed_data_path = \"/home/exPress/express-v2/data/bepro/processed\"\n",
    "feature_list = [\n",
    "                'distance_ball_goal', 'distance_ball_sideline',\n",
    "                'distance_ball_goalline', 'actor_speed', 'angle_to_goal', \n",
    "                'elapsed_time', 'time_since_last_opponent_action', 'def_goal', 'att_goal', 'goal_diff', 'closest_defender_dist', \n",
    "                'closest_defender_speed', 'speed_diff_actor_defender', 'nb_of_3m_radius', 'nb_of_5m_radius','nb_of_10m_radius', \n",
    "                'dist_defender_to_sideline','dist_defender_to_goaline', 'diff_ball_defender_goalline', 'diff_ball_defender_sideline',\n",
    "                'sum_pitch_control'\n",
    "                ]\n",
    "\n",
    "update_features(train_dataset, feature_list, processed_data_path, transform=False, cache_dir=\"/home/exPress/express-v2/data/bepro/feature\")\n",
    "update_features(valid_dataset, feature_list, processed_data_path, transform=False, cache_dir=\"/home/exPress/express-v2/data/bepro/feature\")\n",
    "update_features(test_dataset, feature_list, processed_data_path, transform=False, cache_dir=\"/home/exPress/express-v2/data/bepro/feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e018df08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_dataset (after)] Feature shape before update:\n",
      "  Sample 0: torch.Size([2, 23, 39])\n",
      "  Sample 1: torch.Size([1, 23, 39])\n",
      "  Sample 2: torch.Size([1, 23, 39])\n",
      "[valid dataset (after)] Feature shape before update:\n",
      "  Sample 0: torch.Size([2, 23, 39])\n",
      "  Sample 1: torch.Size([4, 23, 39])\n",
      "  Sample 2: torch.Size([2, 23, 39])\n",
      "[test_dataset (after)] Feature shape before update:\n",
      "  Sample 0: torch.Size([4, 23, 39])\n",
      "  Sample 1: torch.Size([4, 23, 39])\n",
      "  Sample 2: torch.Size([2, 23, 39])\n"
     ]
    }
   ],
   "source": [
    "def print_feature_shape_diff(dataset, dataset_name=\"dataset\"):\n",
    "    print(f\"[{dataset_name}] Feature shape before update:\")\n",
    "    for i in range(3):  # ì•ì˜ 3ê°œ ìƒ˜í”Œë§Œ ì˜ˆì‹œë¡œ í™•ì¸\n",
    "        print(f\"  Sample {i}: {dataset[i]['features'].shape}\")\n",
    "\n",
    "# 1. ì—…ë°ì´íŠ¸ ì „\n",
    "print_feature_shape_diff(train_dataset, \"train_dataset (after)\")\n",
    "print_feature_shape_diff(valid_dataset, \"valid dataset (after)\")\n",
    "print_feature_shape_diff(test_dataset, \"test_dataset (after)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e707b682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying feature reordering based on feature at index 15...\n",
      "Feature reordering complete.\n",
      "Applying feature reordering based on feature at index 15...\n",
      "Feature reordering complete.\n",
      "Applying feature reordering based on feature at index 15...\n",
      "Feature reordering complete.\n"
     ]
    }
   ],
   "source": [
    "def reorder_features_by_distance_to_ball(dataset, distance_feature_idx=14):\n",
    "    \"\"\"\n",
    "    datasetì˜ ê° ìƒ˜í”Œì— ëŒ€í•´ 'features' í…ì„œë¥¼ ê³µê³¼ì˜ ê±°ë¦¬ì— ë”°ë¼ ì¬ì •ë ¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        dataset (list or Dataset object): ê° ìƒ˜í”Œì´ 'features' í‚¤ë¥¼ ê°€ì§„ ë”•ì…”ë„ˆë¦¬ì¸ ë°ì´í„°ì…‹.\n",
    "                                        features í…ì„œëŠ” (B, N, D) í˜•íƒœë¥¼ ê°€ì •í•©ë‹ˆë‹¤.\n",
    "        distance_feature_idx (int): ê³µê³¼ì˜ ê±°ë¦¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” featureì˜ ì¸ë±ìŠ¤ (0-based).\n",
    "                                    (ì—¬ê¸°ì„œëŠ” 14)\n",
    "\n",
    "    Returns:\n",
    "        None: datasetì„ ì§ì ‘ ìˆ˜ì •í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    print(f\"Applying feature reordering based on feature at index {distance_feature_idx}...\")\n",
    "    \n",
    "    for sample_idx in range(len(dataset)):\n",
    "        sample = dataset[sample_idx]\n",
    "        features_tensor = sample['features'] # (B, N, D)\n",
    "\n",
    "        B, N, D = features_tensor.shape\n",
    "\n",
    "        # ê° ì‹œì  (B) ì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ ì •ë ¬ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "        reordered_features = []\n",
    "        for t in range(B): # tëŠ” ì‹œí€€ìŠ¤ì˜ ê° íƒ€ì„ìŠ¤í…\n",
    "            current_time_step_features = features_tensor[t] # (N, D)\n",
    "\n",
    "            # 14ë²ˆì§¸ ì¸ë±ìŠ¤ (ê³µê³¼ì˜ ê±°ë¦¬) í”¼ì²˜ ê°’ë“¤ì„ ì¶”ì¶œ\n",
    "            distances = current_time_step_features[:, distance_feature_idx] # (N,)\n",
    "\n",
    "            # ê±°ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬í•  ì¸ë±ìŠ¤ë¥¼ ì–»ìŒ (ê°€ì¥ ê°€ê¹Œìš´ ì„ ìˆ˜ë¶€í„°)\n",
    "            # torch.argsortëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬\n",
    "            sorted_indices = torch.argsort(distances, dim=0) # (N,)\n",
    "\n",
    "            # ì •ë ¬ëœ ì¸ë±ìŠ¤ì— ë”°ë¼ í˜„ì¬ ì‹œì ì˜ ëª¨ë“  í”¼ì²˜ë¥¼ ì¬ì •ë ¬\n",
    "            reordered_time_step_features = current_time_step_features[sorted_indices] # (N, D)\n",
    "            reordered_features.append(reordered_time_step_features)\n",
    "        \n",
    "        # ì¬ì •ë ¬ëœ ì‹œì ë³„ íŠ¹ì§•ë“¤ì„ ë‹¤ì‹œ (B, N, D) í…ì„œë¡œ í•©ì¹¨\n",
    "        sample['features'] = torch.stack(reordered_features, dim=0) # (B, N, D)\n",
    "        dataset[sample_idx] = sample # ë°ì´í„°ì…‹ì— ì—…ë°ì´íŠ¸ (íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¼ë©´ í•„ìˆ˜)\n",
    "    \n",
    "    print(\"Feature reordering complete.\")\n",
    "\n",
    "reorder_features_by_distance_to_ball(train_dataset, distance_feature_idx=15)\n",
    "reorder_features_by_distance_to_ball(valid_dataset, distance_feature_idx=15)\n",
    "reorder_features_by_distance_to_ball(test_dataset, distance_feature_idx=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca2ca120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([59.1306, 28.6495, 18.4786, 14.0945, 29.1905, 16.3422, 18.5143,  8.9725,\n",
       "        28.8248, 33.3738,  0.7818, 15.5352, 21.6650, 22.0501, 26.6934, 27.3976,\n",
       "        30.8642,  7.7507, 21.0836, 16.8600, 14.8761, 37.6448,  0.0000])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''\n",
    "'distance_ball_goal', 'distance_ball_sideline',\n",
    "'distance_ball_goalline', 'actor_speed', 'angle_to_goal', \n",
    "'elapsed_time', 'time_since_last_opponent_action', 'def_goal', 'att_goal', 'goal_diff', 'closest_defender_dist', \n",
    "'closest_defender_speed', 'speed_diff_actor_defender', 'nb_of_3m_radius', 'nb_of_5m_radius','nb_of_10m_radius', \n",
    "'dist_defender_to_sideline','dist_defender_to_goaline', 'diff_ball_defender_goalline', 'diff_ball_defender_sideline',\n",
    "'sum_pitch_control'\n",
    "\n",
    "''\n",
    "sample = train_dataset[0]\n",
    "sample['features'][0,:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "582a1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seq = 150\n",
    "num_agents = 11\n",
    "use_pressing_intensity = False\n",
    "\n",
    "selected_player_features_idx = [i for i in range(18)] # 0ë¶€í„° 17ê¹Œì§€ 18ê°œ\n",
    "\n",
    "# ê¸€ë¡œë²Œ í”¼ì²˜ (ì˜ˆ: ê²½ê¸° ì „ì²´ì˜ í†µê³„, íŠ¹ì • ì´ë²¤íŠ¸ì˜ ì´í•© ë“±) - ìƒ˜í”Œë‹¹ ë‹¨ì¼ ê°’\n",
    "selected_global_features_idx = [i for i in range(18, 39)] # 18ë¶€í„° 38ê¹Œì§€ 21ê°œ\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "for i in range(len(train_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "    agent_feat = sample['features'][-1:, :, selected_player_features_idx]  # shape: (1, 23, 18)\n",
    "    agent_flat = agent_feat.flatten().numpy()  # shape: (1 Ã— 23 Ã— 18,) â†’ (414,)\n",
    "\n",
    "    # 2. global features: í•œ agent (ì˜ˆ: ì²« ë²ˆì§¸ agent) ê¸°ì¤€ìœ¼ë¡œë§Œ ê°€ì ¸ì˜¤ê¸°\n",
    "    # global_feat = sample['features'][-1, 0, selected_global_features_idx].numpy()  # shape: (20,)\n",
    "    global_feat = sample['features'][-1:, :, selected_global_features_idx].numpy()  # shape: (20,)\n",
    "        \n",
    "    global_flat = global_feat.flatten() # shape: (1 Ã— 23 Ã— 18,) â†’ (414,)\n",
    "\n",
    "    y_tensor = sample['label']\n",
    "\n",
    "    feature_vector = np.concatenate([agent_flat, global_flat])\n",
    "    # feature_vector = agent_flat\n",
    "    \n",
    "    if use_pressing_intensity:\n",
    "        press_intensity = sample['pressing_intensity'][-1:]\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "            \n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    train_features.append(feature_vector)\n",
    "    train_labels.append(y_tensor.item())\n",
    "    \n",
    "valid_features = []\n",
    "valid_labels = []\n",
    "for i in range(len(valid_dataset)):\n",
    "    sample = valid_dataset[i]\n",
    "    agent_feat = sample['features'][-1:, :, selected_player_features_idx]  # shape: (1, 23, 18)\n",
    "    agent_flat = agent_feat.flatten().numpy()  # shape: (1 Ã— 23 Ã— 18,) â†’ (414,)\n",
    "\n",
    "    # 2. global features: í•œ agent (ì˜ˆ: ì²« ë²ˆì§¸ agent) ê¸°ì¤€ìœ¼ë¡œë§Œ ê°€ì ¸ì˜¤ê¸°\n",
    "    global_feat = sample['features'][-1:, :, selected_global_features_idx].numpy()  # shape: (20,)\n",
    "    global_flat = global_feat.flatten()  # shape: (1 Ã— 23 Ã— 18,) â†’ (414,)\n",
    "\n",
    "    y_tensor = sample['label']    \n",
    "    feature_vector = np.concatenate([agent_flat, global_flat])\n",
    "    # feature_vector = agent_flat\n",
    "\n",
    "    if use_pressing_intensity:\n",
    "        press_intensity = sample['pressing_intensity'][-1:]\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "            \n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    valid_features.append(feature_vector)\n",
    "    valid_labels.append(y_tensor.item())\n",
    "\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "for i in range(len(test_dataset)):\n",
    "\n",
    "    sample = test_dataset[i]\n",
    "\n",
    "    agent_feat = sample['features'][-1:, :, selected_player_features_idx]  # shape: (1, 23, 18)\n",
    "    agent_flat = agent_feat.flatten().numpy()  # shape: (1 Ã— 23 Ã— 18,) â†’ (414,)\n",
    "\n",
    "    global_feat = sample['features'][-1:, :, selected_global_features_idx].numpy()  # shape: (20,)\n",
    "    global_flat = agent_feat.flatten()\n",
    "    y_tensor = sample['label']\n",
    "    feature_vector = np.concatenate([agent_flat, global_flat])\n",
    "    # feature_vector = agent_flat\n",
    "    \n",
    "    if use_pressing_intensity:\n",
    "        press_intensity = sample['pressing_intensity'][-1:]\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    test_features.append(feature_vector)\n",
    "    test_labels.append(y_tensor.item())\n",
    "\n",
    "X_train = np.array(train_features)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "X_valid = np.array(valid_features)\n",
    "y_valid = np.array(valid_labels)\n",
    "\n",
    "X_test = np.array(test_features)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bd2785b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 897)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44ac95b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Dataset Distribution Summary\n",
      "========================================\n",
      "Train Set:\n",
      "  Total samples: 6569\n",
      "    Label 0:  4736 samples (72.10%)\n",
      "    Label 1:  1833 samples (27.90%)\n",
      "----------------------------------------\n",
      "Validation Set:\n",
      "  Total samples: 598\n",
      "    Label 0:   433 samples (72.41%)\n",
      "    Label 1:   165 samples (27.59%)\n",
      "----------------------------------------\n",
      "Test Set:\n",
      "  Total samples: 637\n",
      "    Label 0:   468 samples (73.47%)\n",
      "    Label 1:   169 samples (26.53%)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_dataset_distribution(y_train, y_val, y_test):\n",
    "    def _print_split(name, labels):\n",
    "        total = len(labels)\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        print(f\"{name} Set:\")\n",
    "        print(f\"  Total samples: {total}\")\n",
    "        for label, count in zip(unique, counts):\n",
    "            percent = (count / total) * 100\n",
    "            print(f\"    Label {label}: {count:>5} samples ({percent:5.2f}%)\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    print(\"\\nğŸ“Š Dataset Distribution Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    _print_split(\"Train\", y_train)\n",
    "    _print_split(\"Validation\", y_val)\n",
    "    _print_split(\"Test\", y_test)\n",
    "\n",
    "print_dataset_distribution(y_train, y_valid, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3ff0d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost DMatrix objects for train and test sets\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "# Set XGBoost training parameters\n",
    "# params = {\n",
    "#     'objective': 'binary:logistic',  # binary classification\n",
    "#     'eval_metric': 'auc',            # evaluation metric: AUC\n",
    "#     'max_depth': 6,                  # maximum depth of trees\n",
    "#     'eta': 0.1,                      # learning rate\n",
    "#     'seed': 42\n",
    "# }\n",
    "# # Specify the watchlist to evaluate performance on training and test sets during training\n",
    "# num_rounds = 100\n",
    "\n",
    "scale_pos_weight_val = 4736 / 1833 \n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'max_depth': 6,                # ì•½ê°„ ì¤„ì—¬ì„œ ì‹œì‘\n",
    "    'eta': 0.05,                   # í•™ìŠµë¥ ì„ ì¤„ì—¬ì„œ ë” ë§ì€ ë¼ìš´ë“œë¥¼ í•™ìŠµí•˜ë„ë¡ ìœ ë„\n",
    "    'subsample': 0.7,              # ìƒ˜í”Œë§\n",
    "    'colsample_bytree': 0.8,       # í”¼ì²˜ ìƒ˜í”Œë§\n",
    "    'min_child_weight': 4,         # ê¸°ë³¸ê°’ ìœ ì§€ ë˜ëŠ” 2~3 ì‹œë„\n",
    "    'gamma': 0,                  # ê°ë§ˆ ì„¤ì •\n",
    "    'scale_pos_weight': scale_pos_weight_val, # ë¶ˆê· í˜• ì²˜ë¦¬ (ê°€ì¥ ì¤‘ìš”)\n",
    "    'n_estimators': 200,\n",
    "    'seed': 42,\n",
    "    # 'tree_method': 'hist',       # ë°ì´í„°ê°€ í¬ë©´ ì†ë„ í–¥ìƒì„ ìœ„í•´ ì‚¬ìš© ê³ ë ¤ (CPU)\n",
    "    # 'grow_policy': 'lossguide'   # tree_method='hist'ì™€ í•¨ê»˜ ì‚¬ìš© (ë¶ˆê· í˜• ë°ì´í„°ì…‹ì— ìœ ë¦¬í•  ìˆ˜ ìˆìŒ)\n",
    "}\n",
    "\n",
    "num_rounds = 500 # etaë¥¼ ì¤„ì˜€ìœ¼ë¯€ë¡œ ë¼ìš´ë“œ ìˆ˜ë¥¼ ëŠ˜ë¦½ë‹ˆë‹¤.\n",
    "early_stopping_rounds = 30 # ë” ê¸¸ê²Œ ë´ì„œ ìµœì ì˜ ë¼ìš´ë“œ ì°¾ë„ë¡ ì„¤ì •\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a3ba1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.74688\teval-auc:0.61203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-auc:0.78444\teval-auc:0.65245\n",
      "[2]\ttrain-auc:0.81363\teval-auc:0.68917\n",
      "[3]\ttrain-auc:0.82902\teval-auc:0.68362\n",
      "[4]\ttrain-auc:0.84164\teval-auc:0.68968\n",
      "[5]\ttrain-auc:0.84681\teval-auc:0.69474\n",
      "[6]\ttrain-auc:0.85060\teval-auc:0.70727\n",
      "[7]\ttrain-auc:0.85659\teval-auc:0.71311\n",
      "[8]\ttrain-auc:0.86262\teval-auc:0.71211\n",
      "[9]\ttrain-auc:0.86753\teval-auc:0.70724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/expressv2/lib/python3.11/site-packages/xgboost/core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-auc:0.86966\teval-auc:0.70963\n",
      "[11]\ttrain-auc:0.87643\teval-auc:0.70654\n",
      "[12]\ttrain-auc:0.87946\teval-auc:0.70290\n",
      "[13]\ttrain-auc:0.88053\teval-auc:0.70356\n",
      "[14]\ttrain-auc:0.88196\teval-auc:0.70516\n",
      "[15]\ttrain-auc:0.88563\teval-auc:0.70870\n",
      "[16]\ttrain-auc:0.88684\teval-auc:0.70650\n",
      "[17]\ttrain-auc:0.88901\teval-auc:0.70506\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(params, dtrain, num_rounds, watchlist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1965a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# scale_pos_weight_val = 4736 / 1833\n",
    "\n",
    "# model = XGBClassifier(\n",
    "#     objective='binary:logistic',\n",
    "#     eval_metric='auc',\n",
    "#     use_label_encoder=False,\n",
    "#     seed=42,\n",
    "#     scale_pos_weight=scale_pos_weight_val,\n",
    "# )\n",
    "\n",
    "# # parameter grid ì„¤ì •\n",
    "# param_grid = {\n",
    "#     'max_depth': [6, 8],\n",
    "#     'eta': [0.05, 0.1],\n",
    "#     'min_child_weight': [3, 4, 5],\n",
    "#     'subsample': [0.6, 0.7, 0.8],\n",
    "#     'colsample_bytree': [0.8, 0.9],\n",
    "#     'scale_weight' : [1.5, 2, 2.5],\n",
    "#     'gamma': [0, 0.5],\n",
    "#     'n_estimators': [200, 500]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=model,\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='roc_auc',\n",
    "#     cv=3,\n",
    "#     verbose=1,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b687673c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.9, 'eta': 0.05, 'gamma': 0.5, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 200, 'scale_weight': 1.5, 'subsample': 0.8}\n",
      "Best AUC score : 0.5073542756068452\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best AUC score :\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "03cccea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy     : 0.6957\n",
      "AUC          : 0.7051\n",
      "F1-score     : 0.4944 â†‘\n",
      "Brier Score  : 0.2125 â†“\n",
      "Log Loss     : 0.6162 â†“\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, f1_score,\n",
    "    brier_score_loss, log_loss\n",
    ")\n",
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Metric ê³„ì‚°\n",
    "accuracy = accuracy_score(y_valid, y_pred_label)\n",
    "auc = roc_auc_score(y_valid, y_pred)\n",
    "f1 = f1_score(y_valid, y_pred_label)\n",
    "brier = brier_score_loss(y_valid, y_pred)\n",
    "logloss = log_loss(y_valid, y_pred)\n",
    "\n",
    "# ì¶œë ¥\n",
    "print(f\"Accuracy     : {accuracy:.4f}\")\n",
    "print(f\"AUC          : {auc:.4f}\")\n",
    "print(f\"F1-score     : {f1:.4f} â†‘\")            # â†‘ ì¢‹ì„ìˆ˜ë¡ ì¢‹ìŒ\n",
    "print(f\"Brier Score  : {brier:.4f} â†“\")         # â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ\n",
    "print(f\"Log Loss     : {logloss:.4f} â†“\")       # â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ef23bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST SET EVALUATION]\n",
      "Accuracy     : 0.6907\n",
      "AUC          : 0.6836\n",
      "F1-score     : 0.4856 â†‘\n",
      "Brier Score  : 0.2185 â†“\n",
      "Log Loss     : 0.6285 â†“\n"
     ]
    }
   ],
   "source": [
    "# DMatrix ìƒì„±\n",
    "dtest_final = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# ì˜ˆì¸¡ í™•ë¥ ê°’ ë° ì´ì§„ ê²°ê³¼\n",
    "y_pred_test = bst.predict(dtest_final)                       # í™•ë¥ ê°’\n",
    "y_pred_label_test = (y_pred_test > 0.5).astype(int)          # threshold ì ìš©\n",
    "\n",
    "# Metric ê³„ì‚°\n",
    "accuracy_test = accuracy_score(y_test, y_pred_label_test)\n",
    "auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "f1_test = f1_score(y_test, y_pred_label_test)\n",
    "brier_test = brier_score_loss(y_test, y_pred_test)\n",
    "logloss_test = log_loss(y_test, y_pred_test)\n",
    "\n",
    "# ì¶œë ¥\n",
    "print(f\"[TEST SET EVALUATION]\")\n",
    "print(f\"Accuracy     : {accuracy_test:.4f}\")\n",
    "print(f\"AUC          : {auc_test:.4f}\")\n",
    "print(f\"F1-score     : {f1_test:.4f} â†‘\")\n",
    "print(f\"Brier Score  : {brier_test:.4f} â†“\")\n",
    "print(f\"Log Loss     : {logloss_test:.4f} â†“\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bc7c6",
   "metadata": {},
   "source": [
    "# 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seq = 150\n",
    "num_agents = 11\n",
    "use_pressing_intensity = False\n",
    "selected_features_idx = [1, 2, 4, 7]\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "for i in range(len(train_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-90:]\n",
    "    press_intensity = sample['pressing_intensity'][-90:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "            \n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    train_features.append(feature_vector)\n",
    "    train_labels.append(y_tensor.item())\n",
    "\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "for i in range(len(test_dataset)):\n",
    "    sample = test_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-90:]\n",
    "    press_intensity = sample['pressing_intensity'][-90:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    \n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    test_features.append(feature_vector)\n",
    "    test_labels.append(y_tensor.item())\n",
    "\n",
    "X_train = np.array(train_features)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = np.array(test_features)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82432f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_distribution(y_train, y_val, y_test):\n",
    "    def _print_split(name, labels):\n",
    "        total = len(labels)\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        print(f\"{name} Set:\")\n",
    "        print(f\"  Total samples: {total}\")\n",
    "        for label, count in zip(unique, counts):\n",
    "            percent = (count / total) * 100\n",
    "            print(f\"    Label {label}: {count:>5} samples ({percent:5.2f}%)\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    print(\"\\nğŸ“Š Dataset Distribution Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    _print_split(\"Train\", y_train)\n",
    "    _print_split(\"Validation\", y_val)\n",
    "    _print_split(\"Test\", y_test)\n",
    "\n",
    "print_dataset_distribution(y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e48d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost DMatrix objects for train and test sets\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Set XGBoost training parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # binary classification\n",
    "    'eval_metric': 'auc',            # evaluation metric: AUC\n",
    "    'max_depth': 6,                  # maximum depth of trees\n",
    "    'eta': 0.1,                      # learning rate\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Specify the watchlist to evaluate performance on training and test sets during training\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ef086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model with early stopping on the evaluation set\n",
    "bst = xgb.train(params, dtrain, num_rounds, watchlist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96af079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5df0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb1665e",
   "metadata": {},
   "source": [
    "# 2. SoccerMap / exPress Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d976f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import os\n",
    "os.chdir('/home/work/MHL/express-v2')\n",
    "import argparse # To accept checkpoint path as argument\n",
    "\n",
    "# Import project modules\n",
    "# import config  # Import static configurations\n",
    "from model import PytorchSoccerMapModel # Import Lightning model\n",
    "from datasets import PressingSequenceDataset, SoccerMapInputDataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a1fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42, workers=True) # Ensure reproducibility\n",
    "\n",
    "DATA_PATH = \"/data/MHL/pressing-intensity\" # Path where pickled datasets are saved\n",
    "test_dataset = SoccerMapInputDataset(os.path.join(DATA_PATH, \"test_dataset.pkl\"))\n",
    "\n",
    "if len(test_dataset) == 0:\n",
    "    print(\"Loaded test dataset is empty. Exiting.\")\n",
    "\n",
    "# Custom collate function to handle potential None values from dataset errors\n",
    "def collate_fn_skip_none(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    if not batch: return None\n",
    "    try: return torch.utils.data.dataloader.default_collate(batch)\n",
    "    except RuntimeError: return None # Skip batch if collation error\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    # collate_fn=collate_fn_skip_none\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aabfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Train a pressing evaluation model.\")\n",
    "# parser.add_argument(\"--model_type\", type=str, default=\"soccermap\", choices=['soccermap', 'xgboost', 'exPress'], help=\"Path to the model checkpoint (.ckpt) file saved during training.\")\n",
    "# parser.add_argument(\"--root_path\", type=str, default=\"/data/MHL/pressing-intensity\", help=\"Path to the data file.\")\n",
    "parser.add_argument(\"--model_type\", type=str, default=\"soccermap\", choices=['soccermap', 'xgboost', 'exPress'], help=\"Path to the model checkpoint (.ckpt) file saved during training.\")\n",
    "parser.add_argument(\"--root_path\", type=str, default=\"/data/MHL/pressing-intensity\", help=\"Path to the data file.\")\n",
    "parser.add_argument(\"--mode\", type=str, default=\"train\", choices=['train', 'test'], help=\"Mode: 'train' or 'test'.\")\n",
    "parser.add_argument(\"--ckpt_path\", type=str, default=None, help=\"Path to checkpoint file (Required for 'test' mode).\")\n",
    "parser.add_argument(\"--params_path\", type=str, default=\"params.json\", help=\"Path to the JSON containing configurations.\")\n",
    "parser.add_argument(\"--seed\", type=int, default=42, help=\"Seed number.\")\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "args.mode = 'test'\n",
    "args.model_type = \"exPress\"\n",
    "args.ckpt_path = \"/data/MHL/pressing-intensity/checkpoints/exPress-epoch=28-val_loss=0.49.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcd43e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from components import press\n",
    "\n",
    "\n",
    "component_dict = {\n",
    "                    \"soccermap\": press.SoccerMapComponent,\n",
    "                    \"exPress\": press.exPressComponent,\n",
    "                }\n",
    "\n",
    "exp = component_dict[args.model_type](args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193af97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expressv2",
   "language": "python",
   "name": "expressv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
