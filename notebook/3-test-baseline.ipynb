{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be2b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 07:52:00.270246: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-14 07:52:00.270294: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-14 07:52:00.270327: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-14 07:52:00.278843: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-14 07:52:01.241611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/exPress/express-v2\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import PressingSequenceDataset, SoccerMapInputDataset\n",
    "import config as C\n",
    "import features as F\n",
    "from bisect import bisect_right\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31019cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6569, 637)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/home/exPress/express-v2/data/bepro/pressing_intensity\"\n",
    "\n",
    "with open(f\"{data_path}/train_dataset.pkl\", \"rb\") as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "# with open(f\"{data_path}/valid_dataset.pkl\", \"rb\") as f:\n",
    "#     valid_dataset = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(f\"{data_path}/test_dataset.pkl\", \"rb\") as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0669211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Game IDs: (34, ['126285', '126293', '126298', '126306', '126309', '126315', '126319', '126325', '126332', '126341', '126348', '126350', '126356', '126364', '126367', '126378', '126380', '126386', '126391', '126401', '126408', '126411', '126418', '126424', '126429', '126433', '126444', '126448', '126455', '126458', '126466', '126473', '126476', '153364'])\n",
      "Test Game IDs: (3, ['153381', '153385', '153387'])\n"
     ]
    }
   ],
   "source": [
    "def check_game_ids(dataset):\n",
    "    game_ids = set()\n",
    "    for idx, sample in enumerate(dataset):\n",
    "        game_id, _, _ = sample['match_info'].split('-')\n",
    "        game_ids.add(game_id)\n",
    "    return len(game_ids), sorted(game_ids)\n",
    "\n",
    "print(\"Train Game IDs:\", check_game_ids(train_dataset))\n",
    "print(\"Test Game IDs:\", check_game_ids(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4423e5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features : torch.Size([3, 23, 18])\n",
      "Pressing Intensity : torch.Size([3, 11, 11])\n",
      "Labels : 0\n",
      "Presser ID : 248890\n",
      "Players Order : ['250079', '250101', '250102', '500133', '500135', '500139', '500140', '500141', '62365', '62386', '77414', '139210', '143410', '161110', '187326', '188266', '248890', '344466', '344467', '62009', '62038', '77579', 'ball']\n",
      "match info : 126285-1.0-522\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "\n",
    "print(f\"Features : {sample['features'].shape}\")\n",
    "print(f\"Pressing Intensity : {sample['pressing_intensity'].shape}\")\n",
    "print(f\"Labels : {sample['label']}\")\n",
    "print(f\"Presser ID : {sample['presser_id']}\")\n",
    "print(f\"Players Order : {sample['agent_order']}\")\n",
    "print(f\"match info : {sample['match_info']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39086842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def compute_second_half_offset(tracking_df):\n",
    "\n",
    "    df = tracking_df.copy()\n",
    "    df['timestamp'] = pd.to_timedelta(df['timestamp'])\n",
    "\n",
    "    # 전반 종료 시점\n",
    "    first_half_end = df[df['period_id'] == 1]['timestamp'].max()\n",
    "\n",
    "    # 후반 시작 시점\n",
    "    second_half_start = df[df['period_id'] == 2]['timestamp'].min()\n",
    "\n",
    "    # offset 계산 (후반 timestamp에 더할 시간)\n",
    "    offset = (first_half_end - second_half_start).total_seconds()\n",
    "\n",
    "    return offset\n",
    "\n",
    "def update_features(dataset, feature_list, processed_data_path, cache_dir=\"feature_cache\"):\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    game_sample_map = defaultdict(list)\n",
    "\n",
    "    # 1. game_id 기준으로 샘플 인덱스와 frame_id를 모음\n",
    "    for idx, sample in enumerate(dataset): # dataset.__len__에 의해 결정되는 길이만큼 루프\n",
    "        game_id, _, frame_id_str = sample['match_info'].split('-')\n",
    "        frame_id = int(frame_id_str)\n",
    "        game_sample_map[game_id].append((idx, frame_id))\n",
    "\n",
    "    # 2. game_id 단위로 모든 처리 (데이터 로드, timestamp 매핑, 피처 계산, 데이터셋 업데이트)\n",
    "    for game_id, frame_infos_for_game in game_sample_map.items():\n",
    "        print(f\"\\n--- Processing Game ID: {game_id} ---\")\n",
    "\n",
    "        # 2-1. 해당 game_id의 데이터 로드\n",
    "        tracking_df = pd.read_csv(os.path.join(processed_data_path, game_id, f\"{game_id}_traces.csv\"))\n",
    "        events_df = pd.read_csv(os.path.join(processed_data_path, game_id, f\"{game_id}_merged.csv\"))\n",
    "        teams_df = pd.read_csv(os.path.join(processed_data_path, game_id, f\"{game_id}_teams.csv\"))\n",
    "        events_df = events_df.sort_values(\"timestamp\")\n",
    "        events_df[\"time_seconds\"] = pd.to_numeric(events_df[\"time_seconds\"], errors=\"coerce\")\n",
    "\n",
    "        offset = compute_second_half_offset(tracking_df)\n",
    "\n",
    "        # 2-2. frame_id -> timestamp 매핑 (스코프가 이 루프 내부로 제한됨)\n",
    "        frame_id_to_ts = {}\n",
    "        for fid in [fid for _, fid in frame_infos_for_game]: # 현재 game_id에 해당하는 fid들만 사용\n",
    "            row = tracking_df[tracking_df[\"frame_id\"] == fid]\n",
    "            if not row.empty:\n",
    "                ts = pd.to_timedelta(row.iloc[0][\"timestamp\"]).total_seconds()\n",
    "                if row.iloc[0][\"period_id\"] == 2:\n",
    "                    ts += offset\n",
    "                frame_id_to_ts[fid] = ts\n",
    "\n",
    "        # 2-3. 피처 계산 및 버퍼링 (현재 game_id에 속하는 샘플들만 처리)\n",
    "        # 이 버퍼는 현재 game_id 내에서만 사용됩니다.\n",
    "        current_game_sample_feature_buffer = defaultdict(list) \n",
    "\n",
    "        for feature_name in feature_list: # 각 피처 이름에 대해\n",
    "            func = getattr(F, feature_name)\n",
    "            game_feature_dir = os.path.join(cache_dir, game_id)\n",
    "            os.makedirs(game_feature_dir, exist_ok=True)\n",
    "\n",
    "            cache_path = os.path.join(cache_dir, game_id, f\"{game_id}_{feature_name}.npy\")\n",
    "            feature_cache = None\n",
    "            \n",
    "            if os.path.exists(cache_path):                \n",
    "                feature_cache = np.load(cache_path, allow_pickle=True).item()  # dict: sample_idx -> (B, 1)\n",
    "            else:\n",
    "                feature_cache = {}\n",
    "\n",
    "            feature_updated = False\n",
    "\n",
    "            # 현재 game_id의 샘플들만 순회\n",
    "            for sample_idx, fid in frame_infos_for_game: \n",
    "                if fid not in frame_id_to_ts:\n",
    "                    print(f\"WARN: Skipping sample_idx {sample_idx}, fid {fid} for game {game_id} as timestamp not found.\")\n",
    "                    continue\n",
    "                ts = frame_id_to_ts[fid]\n",
    "                current_sample_data_dict = dataset[sample_idx] \n",
    "                feature_tensor = current_sample_data_dict['features'] \n",
    "                B, N, D = feature_tensor.shape\n",
    "\n",
    "                if sample_idx in feature_cache:\n",
    "                    feat_val = feature_cache[sample_idx]\n",
    "                else:                \n",
    "                    full_past_events = events_df[events_df[\"time_seconds\"] < ts].sort_values(\"time_seconds\", ascending=False)\n",
    "                    past_events = full_past_events.head(B)\n",
    "\n",
    "                    if past_events.empty:\n",
    "                        feat_val = np.full((B, 1), np.nan, dtype=np.float32)\n",
    "                    else:\n",
    "                        if feature_name == \"sum_pitch_control\":\n",
    "                            feat_val = func(past_events, teams_df)                    \n",
    "                        elif feature_name in [\"time_since_last_opponent_action\", \"cumul_goal_att\", \"cumul_goal_def\", \"goaldiff\"]:\n",
    "                            feat_val = func(past_events, events_df)\n",
    "                        else:\n",
    "                            feat_val = func(past_events)\n",
    "                    \n",
    "                        if isinstance(feat_val, pd.DataFrame):\n",
    "                            feat_val = feat_val.values.astype(np.float32)\n",
    "                        elif isinstance(feat_val, np.ndarray):\n",
    "                            feat_val = feat_val.astype(np.float32)\n",
    "                    \n",
    "                        if feat_val.ndim == 1:\n",
    "                            feat_val = feat_val.reshape(-1, 1) # 항상 (B, 1) 또는 (이벤트 수, 1) 형태로 유지\n",
    "\n",
    "                    feature_cache[sample_idx] = feat_val\n",
    "                    feature_updated = True\n",
    "\n",
    "                new_feature_tensor = torch.tensor(feat_val, dtype=torch.float32).unsqueeze(1).expand(-1, N, -1) # (B, N, F)\n",
    "                current_game_sample_feature_buffer[sample_idx].append(new_feature_tensor)\n",
    "                # print(f\"DEBUG: New feature '{feature_name}' for sample {sample_idx} shape: {new_feature_tensor.shape}\", flush=True)\n",
    "            \n",
    "            if feature_updated:\n",
    "                np.save(cache_path, feature_cache)\n",
    "                print(f\"Saved cached feature for {feature_name} (game {game_id})\")\n",
    "\n",
    "        # 2-4. 현재 game_id에 대한 모든 피처 계산이 끝나면, dataset에 최종적으로 업데이트\n",
    "        for sample_idx, new_feats_for_sample in current_game_sample_feature_buffer.items():\n",
    "            # dataset에서 해당 sample_idx의 현재 데이터 딕셔너리를 가져옵니다.\n",
    "            current_sample_data_dict = dataset[sample_idx] # __getitem__ 호출\n",
    "\n",
    "            original_feature_tensor = current_sample_data_dict['features'] # 현재 features 텐서\n",
    "\n",
    "            # 새롭게 추가될 모든 피처 텐서들을 dim=-1을 기준으로 횡으로 합칩니다.\n",
    "            concat_all_new_features = torch.cat(new_feats_for_sample, dim=-1) \n",
    "\n",
    "            # 기존 피처 텐서와 새로 합쳐진 피처 텐서를 다시 dim=-1을 기준으로 합칩니다.\n",
    "            final_concatenated_feature_tensor = torch.cat([original_feature_tensor, concat_all_new_features], dim=-1)\n",
    "\n",
    "            # 업데이트된 features 텐서를 딕셔너리에 다시 할당합니다.\n",
    "            current_sample_data_dict['features'] = final_concatenated_feature_tensor\n",
    "\n",
    "            # dataset의 __setitem__을 호출하여 데이터셋 내부의 실제 데이터를 업데이트합니다.\n",
    "            # 이 라인이 실행될 때 __setitem__이 없으면 TypeError가 발생하고,\n",
    "            # __setitem__이 잘못 구현되면 IndexError가 발생합니다.\n",
    "            dataset[sample_idx] = current_sample_data_dict \n",
    "\n",
    "            # print(f\"DEBUG: Final shape for sample {sample_idx} in game {game_id}: {dataset[sample_idx]['features'].shape}\", flush=True)\n",
    "            # 이 print는 __getitem__이 호출되어 반환된 값을 보여줍니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cd98db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_dataset (before)] Feature shape before update:\n",
      "  Sample 0: torch.Size([3, 23, 18])\n",
      "  Sample 1: torch.Size([4, 23, 18])\n",
      "  Sample 2: torch.Size([2, 23, 18])\n",
      "[test_dataset (before)] Feature shape before update:\n",
      "  Sample 0: torch.Size([2, 23, 18])\n",
      "  Sample 1: torch.Size([2, 23, 18])\n",
      "  Sample 2: torch.Size([1, 23, 18])\n"
     ]
    }
   ],
   "source": [
    "def print_feature_shape_diff(dataset, dataset_name=\"dataset\"):\n",
    "    print(f\"[{dataset_name}] Feature shape before update:\")\n",
    "    for i in range(3):  # 앞의 3개 샘플만 예시로 확인\n",
    "        print(f\"  Sample {i}: {dataset[i]['features'].shape}\")\n",
    "\n",
    "# 1. 업데이트 전\n",
    "print_feature_shape_diff(train_dataset, \"train_dataset (before)\")\n",
    "print_feature_shape_diff(test_dataset, \"test_dataset (before)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134fceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Game ID: 126293 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 10305.42it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 1/1 [00:00<00:00, 4534.38it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 1/1 [00:00<00:00, 6864.65it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 3/3 [00:00<00:00, 11037.64it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 3/3 [00:00<00:00, 11428.62it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 3/3 [00:00<00:00, 12312.05it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 2/2 [00:00<00:00, 10242.50it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 2/2 [00:00<00:00, 11983.73it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 3/3 [00:00<00:00, 11356.42it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 3/3 [00:00<00:00, 11439.01it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 3/3 [00:00<00:00, 11325.75it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 3/3 [00:00<00:00, 10894.30it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 1/1 [00:00<00:00, 7543.71it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 1/1 [00:00<00:00, 7231.56it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 2/2 [00:00<00:00, 9320.68it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 3/3 [00:00<00:00, 12570.34it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 2/2 [00:00<00:00, 10852.02it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 1/1 [00:00<00:00, 7410.43it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 2/2 [00:00<00:00, 12000.87it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 1/1 [00:00<00:00, 2985.27it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 5/5 [00:00<00:00, 7068.26it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 2/2 [00:00<00:00, 12652.50it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 4/4 [00:00<00:00, 11790.03it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 2/2 [00:00<00:00, 12409.18it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 2/2 [00:00<00:00, 11554.56it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 3/3 [00:00<00:00, 11737.79it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 3/3 [00:00<00:00, 6436.27it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 4/4 [00:00<00:00, 11452.02it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 2/2 [00:00<00:00, 10143.42it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 4/4 [00:00<00:00, 11320.66it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 1/1 [00:00<00:00, 7503.23it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 3/3 [00:00<00:00, 11184.81it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 4/4 [00:00<00:00, 12237.21it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 3/3 [00:00<00:00, 10782.27it/s]\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "/home/exPress/express-v2/datatools/pitch_control.py:245: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  checksum = np.sum( PPCFa + PPCFd ) / float(count)#float(n_grid_cells_y*n_grid_cells_x )\n",
      "100%|██████████| 3/3 [00:00<00:00, 10364.84it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_data_path = \"/home/exPress/express-v2/data/bepro/processed\"\n",
    "feature_list = [\n",
    "                # 'distance_ball_goal','distance_ball_sideline', 'distance_ball_goalline', 'get_actor_speed', 'angle_to_goal', \n",
    "                # 'compute_time_elapsed','get_min_defender_distance', 'get_closest_defender_speed', 'get_speed_diff_actor_defender',\n",
    "                # 'nb_of_3m_radius', 'nb_of_5m_radius','nb_of_10m_radius', 'get_dist_defender_to_sideline','get_dist_defender_to_goaline',\n",
    "                'sum_pitch_control'\n",
    "                ]\n",
    "\n",
    "update_features(train_dataset, feature_list, processed_data_path, cache_dir=\"/home/exPress/express-v2/data/bepro/feature\")\n",
    "update_features(test_dataset, feature_list, processed_data_path, cache_dir=\"/home/exPress/express-v2/data/bepro/feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5f22a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_csv('/home/exPress/express-v2/data/bepro/processed/126298/126298_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95787556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>original_event_id</th>\n",
       "      <th>action_id</th>\n",
       "      <th>period_id</th>\n",
       "      <th>time_seconds</th>\n",
       "      <th>relative_time_seconds</th>\n",
       "      <th>relative_player_id</th>\n",
       "      <th>reactor_team_id</th>\n",
       "      <th>reactor_player_id</th>\n",
       "      <th>type_name</th>\n",
       "      <th>...</th>\n",
       "      <th>H06_y</th>\n",
       "      <th>H07_y</th>\n",
       "      <th>H08_y</th>\n",
       "      <th>H09_y</th>\n",
       "      <th>H10_y</th>\n",
       "      <th>H14_y</th>\n",
       "      <th>H16_y</th>\n",
       "      <th>H18_y</th>\n",
       "      <th>H19_y</th>\n",
       "      <th>ball_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.967</td>\n",
       "      <td>2.067</td>\n",
       "      <td>407605.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Pass</td>\n",
       "      <td>...</td>\n",
       "      <td>12.408782</td>\n",
       "      <td>-1.133164</td>\n",
       "      <td>-30.381690</td>\n",
       "      <td>0.282555</td>\n",
       "      <td>-10.505899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.203899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Pass Received</td>\n",
       "      <td>...</td>\n",
       "      <td>12.013645</td>\n",
       "      <td>-1.181525</td>\n",
       "      <td>-30.856145</td>\n",
       "      <td>0.239845</td>\n",
       "      <td>-9.762821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.721556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126298</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.033</td>\n",
       "      <td>4.200</td>\n",
       "      <td>345446.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Pass</td>\n",
       "      <td>...</td>\n",
       "      <td>13.059672</td>\n",
       "      <td>-1.067999</td>\n",
       "      <td>-31.521623</td>\n",
       "      <td>1.178115</td>\n",
       "      <td>-9.355349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126298</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Pass Received</td>\n",
       "      <td>...</td>\n",
       "      <td>14.822376</td>\n",
       "      <td>-2.185743</td>\n",
       "      <td>-31.445433</td>\n",
       "      <td>1.805146</td>\n",
       "      <td>-8.132191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.625385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126298</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.485</td>\n",
       "      <td>7.533</td>\n",
       "      <td>250899.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Pass</td>\n",
       "      <td>...</td>\n",
       "      <td>14.219126</td>\n",
       "      <td>-4.111640</td>\n",
       "      <td>-30.602459</td>\n",
       "      <td>3.593756</td>\n",
       "      <td>-7.740082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.541895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>126298</td>\n",
       "      <td>3525.0</td>\n",
       "      <td>2962</td>\n",
       "      <td>2</td>\n",
       "      <td>6501.767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4648</td>\n",
       "      <td>62365</td>\n",
       "      <td>Duel</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.870507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.206191</td>\n",
       "      <td>-5.001248</td>\n",
       "      <td>-10.750800</td>\n",
       "      <td>-11.346866</td>\n",
       "      <td>0.788394</td>\n",
       "      <td>-13.771624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>126298</td>\n",
       "      <td>3529.0</td>\n",
       "      <td>2963</td>\n",
       "      <td>2</td>\n",
       "      <td>6503.855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Recovery</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.604813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-18.163922</td>\n",
       "      <td>-8.160125</td>\n",
       "      <td>-20.270517</td>\n",
       "      <td>-16.488018</td>\n",
       "      <td>-2.572863</td>\n",
       "      <td>-22.642875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>126298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2964</td>\n",
       "      <td>2</td>\n",
       "      <td>6503.856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Carry</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.604813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-18.163922</td>\n",
       "      <td>-8.160125</td>\n",
       "      <td>-20.270517</td>\n",
       "      <td>-16.488018</td>\n",
       "      <td>-2.572863</td>\n",
       "      <td>-22.642875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>126298</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>2965</td>\n",
       "      <td>2</td>\n",
       "      <td>6505.567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Pass</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.269982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24.757684</td>\n",
       "      <td>-11.648197</td>\n",
       "      <td>-26.699439</td>\n",
       "      <td>-22.051588</td>\n",
       "      <td>-4.830030</td>\n",
       "      <td>-28.950543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>126298</td>\n",
       "      <td>3531.0</td>\n",
       "      <td>2966</td>\n",
       "      <td>2</td>\n",
       "      <td>6505.634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Block</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.269982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24.919647</td>\n",
       "      <td>-11.702358</td>\n",
       "      <td>-26.832738</td>\n",
       "      <td>-22.174364</td>\n",
       "      <td>-4.862890</td>\n",
       "      <td>-29.546704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2967 rows × 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      game_id  original_event_id  action_id  period_id  time_seconds  \\\n",
       "0      126298                0.0          0          1         0.967   \n",
       "1      126298                1.0          1          1         2.067   \n",
       "2      126298                2.0          2          1         3.033   \n",
       "3      126298                3.0          3          1         4.200   \n",
       "4      126298                4.0          4          1         5.485   \n",
       "...       ...                ...        ...        ...           ...   \n",
       "2962   126298             3525.0       2962          2      6501.767   \n",
       "2963   126298             3529.0       2963          2      6503.855   \n",
       "2964   126298                NaN       2964          2      6503.856   \n",
       "2965   126298             3530.0       2965          2      6505.567   \n",
       "2966   126298             3531.0       2966          2      6505.634   \n",
       "\n",
       "      relative_time_seconds  relative_player_id  reactor_team_id  \\\n",
       "0                     2.067            407605.0               -1   \n",
       "1                       NaN                -1.0               -1   \n",
       "2                     4.200            345446.0               -1   \n",
       "3                       NaN                -1.0               -1   \n",
       "4                     7.533            250899.0               -1   \n",
       "...                     ...                 ...              ...   \n",
       "2962                    NaN                 NaN             4648   \n",
       "2963                    NaN                -1.0               -1   \n",
       "2964                    NaN                 NaN               -1   \n",
       "2965                    NaN                -1.0               -1   \n",
       "2966                    NaN                -1.0               -1   \n",
       "\n",
       "      reactor_player_id      type_name  ...      H06_y     H07_y      H08_y  \\\n",
       "0                    -1           Pass  ...  12.408782 -1.133164 -30.381690   \n",
       "1                    -1  Pass Received  ...  12.013645 -1.181525 -30.856145   \n",
       "2                    -1           Pass  ...  13.059672 -1.067999 -31.521623   \n",
       "3                    -1  Pass Received  ...  14.822376 -2.185743 -31.445433   \n",
       "4                    -1           Pass  ...  14.219126 -4.111640 -30.602459   \n",
       "...                 ...            ...  ...        ...       ...        ...   \n",
       "2962              62365           Duel  ...  -1.870507       NaN        NaN   \n",
       "2963                 -1       Recovery  ...  -2.604813       NaN        NaN   \n",
       "2964                 -1          Carry  ...  -2.604813       NaN        NaN   \n",
       "2965                 -1           Pass  ...  -2.269982       NaN        NaN   \n",
       "2966                 -1          Block  ...  -2.269982       NaN        NaN   \n",
       "\n",
       "         H09_y      H10_y      H14_y      H16_y      H18_y     H19_y  \\\n",
       "0     0.282555 -10.505899        NaN        NaN        NaN       NaN   \n",
       "1     0.239845  -9.762821        NaN        NaN        NaN       NaN   \n",
       "2     1.178115  -9.355349        NaN        NaN        NaN       NaN   \n",
       "3     1.805146  -8.132191        NaN        NaN        NaN       NaN   \n",
       "4     3.593756  -7.740082        NaN        NaN        NaN       NaN   \n",
       "...        ...        ...        ...        ...        ...       ...   \n",
       "2962       NaN -10.206191  -5.001248 -10.750800 -11.346866  0.788394   \n",
       "2963       NaN -18.163922  -8.160125 -20.270517 -16.488018 -2.572863   \n",
       "2964       NaN -18.163922  -8.160125 -20.270517 -16.488018 -2.572863   \n",
       "2965       NaN -24.757684 -11.648197 -26.699439 -22.051588 -4.830030   \n",
       "2966       NaN -24.919647 -11.702358 -26.832738 -22.174364 -4.862890   \n",
       "\n",
       "         ball_y  \n",
       "0      0.203899  \n",
       "1     -0.721556  \n",
       "2      0.045211  \n",
       "3     15.625385  \n",
       "4     13.541895  \n",
       "...         ...  \n",
       "2962 -13.771624  \n",
       "2963 -22.642875  \n",
       "2964 -22.642875  \n",
       "2965 -28.950543  \n",
       "2966 -29.546704  \n",
       "\n",
       "[2967 rows x 286 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582a1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seq = 150\n",
    "num_agents = 11\n",
    "use_pressing_intensity = True\n",
    "selected_features_idx = [i for i in range(18)]\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "for i in range(len(train_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-1:]\n",
    "    press_intensity = sample['pressing_intensity'][-1:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "            \n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    train_features.append(feature_vector)\n",
    "    train_labels.append(y_tensor.item())\n",
    "\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "for i in range(len(test_dataset)):\n",
    "    sample = test_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-1:]\n",
    "    press_intensity = sample['pressing_intensity'][-1:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    \n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    test_features.append(feature_vector)\n",
    "    test_labels.append(y_tensor.item())\n",
    "\n",
    "X_train = np.array(train_features)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = np.array(test_features)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c93e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 18])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ac95b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Dataset Distribution Summary\n",
      "========================================\n",
      "Train Set:\n",
      "  Total samples: 5922\n",
      "    Label 0:  4361 samples (73.64%)\n",
      "    Label 1:  1561 samples (26.36%)\n",
      "----------------------------------------\n",
      "Validation Set:\n",
      "  Total samples: 1481\n",
      "    Label 0:  1101 samples (74.34%)\n",
      "    Label 1:   380 samples (25.66%)\n",
      "----------------------------------------\n",
      "Test Set:\n",
      "  Total samples: 658\n",
      "    Label 0:   547 samples (83.13%)\n",
      "    Label 1:   111 samples (16.87%)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_dataset_distribution(y_train, y_val, y_test):\n",
    "    def _print_split(name, labels):\n",
    "        total = len(labels)\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        print(f\"{name} Set:\")\n",
    "        print(f\"  Total samples: {total}\")\n",
    "        for label, count in zip(unique, counts):\n",
    "            percent = (count / total) * 100\n",
    "            print(f\"    Label {label}: {count:>5} samples ({percent:5.2f}%)\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    print(\"\\n📊 Dataset Distribution Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    _print_split(\"Train\", y_train)\n",
    "    _print_split(\"Validation\", y_val)\n",
    "    _print_split(\"Test\", y_test)\n",
    "\n",
    "print_dataset_distribution(y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ff0d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost DMatrix objects for train and test sets\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Set XGBoost training parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # binary classification\n",
    "    'eval_metric': 'auc',            # evaluation metric: AUC\n",
    "    'max_depth': 6,                  # maximum depth of trees\n",
    "    'eta': 0.1,                      # learning rate\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Specify the watchlist to evaluate performance on training and test sets during training\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a3ba1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.76474\teval-auc:0.58872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/expressv2/lib/python3.11/site-packages/xgboost/core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-auc:0.79538\teval-auc:0.60409\n",
      "[2]\ttrain-auc:0.81498\teval-auc:0.63239\n",
      "[3]\ttrain-auc:0.83127\teval-auc:0.64188\n",
      "[4]\ttrain-auc:0.83337\teval-auc:0.64854\n",
      "[5]\ttrain-auc:0.83850\teval-auc:0.65784\n",
      "[6]\ttrain-auc:0.84749\teval-auc:0.65705\n",
      "[7]\ttrain-auc:0.86106\teval-auc:0.66110\n",
      "[8]\ttrain-auc:0.86346\teval-auc:0.66360\n",
      "[9]\ttrain-auc:0.87747\teval-auc:0.66454\n",
      "[10]\ttrain-auc:0.89042\teval-auc:0.66611\n",
      "[11]\ttrain-auc:0.89713\teval-auc:0.66332\n",
      "[12]\ttrain-auc:0.90123\teval-auc:0.66548\n",
      "[13]\ttrain-auc:0.90507\teval-auc:0.66677\n",
      "[14]\ttrain-auc:0.91075\teval-auc:0.66829\n",
      "[15]\ttrain-auc:0.91485\teval-auc:0.66997\n",
      "[16]\ttrain-auc:0.91735\teval-auc:0.67385\n",
      "[17]\ttrain-auc:0.92745\teval-auc:0.67296\n",
      "[18]\ttrain-auc:0.92733\teval-auc:0.67467\n",
      "[19]\ttrain-auc:0.93228\teval-auc:0.67536\n",
      "[20]\ttrain-auc:0.93604\teval-auc:0.67778\n",
      "[21]\ttrain-auc:0.93696\teval-auc:0.67840\n",
      "[22]\ttrain-auc:0.93916\teval-auc:0.67838\n",
      "[23]\ttrain-auc:0.94082\teval-auc:0.67863\n",
      "[24]\ttrain-auc:0.94757\teval-auc:0.67519\n",
      "[25]\ttrain-auc:0.95109\teval-auc:0.67647\n",
      "[26]\ttrain-auc:0.95353\teval-auc:0.67524\n",
      "[27]\ttrain-auc:0.95810\teval-auc:0.67672\n",
      "[28]\ttrain-auc:0.96083\teval-auc:0.67652\n",
      "[29]\ttrain-auc:0.96151\teval-auc:0.67753\n",
      "[30]\ttrain-auc:0.96406\teval-auc:0.67887\n",
      "[31]\ttrain-auc:0.96710\teval-auc:0.67812\n",
      "[32]\ttrain-auc:0.97031\teval-auc:0.67754\n",
      "[33]\ttrain-auc:0.97128\teval-auc:0.67982\n",
      "[34]\ttrain-auc:0.97284\teval-auc:0.67946\n",
      "[35]\ttrain-auc:0.97418\teval-auc:0.67962\n",
      "[36]\ttrain-auc:0.97518\teval-auc:0.68058\n",
      "[37]\ttrain-auc:0.97701\teval-auc:0.68148\n",
      "[38]\ttrain-auc:0.97859\teval-auc:0.68201\n",
      "[39]\ttrain-auc:0.98021\teval-auc:0.68088\n",
      "[40]\ttrain-auc:0.98128\teval-auc:0.68154\n",
      "[41]\ttrain-auc:0.98277\teval-auc:0.68053\n",
      "[42]\ttrain-auc:0.98422\teval-auc:0.67998\n",
      "[43]\ttrain-auc:0.98527\teval-auc:0.67974\n",
      "[44]\ttrain-auc:0.98587\teval-auc:0.67973\n",
      "[45]\ttrain-auc:0.98681\teval-auc:0.68114\n",
      "[46]\ttrain-auc:0.98764\teval-auc:0.68151\n",
      "[47]\ttrain-auc:0.98834\teval-auc:0.68375\n",
      "[48]\ttrain-auc:0.98890\teval-auc:0.68402\n",
      "[49]\ttrain-auc:0.98983\teval-auc:0.68471\n",
      "[50]\ttrain-auc:0.99032\teval-auc:0.68526\n",
      "[51]\ttrain-auc:0.99082\teval-auc:0.68482\n",
      "[52]\ttrain-auc:0.99127\teval-auc:0.68551\n",
      "[53]\ttrain-auc:0.99189\teval-auc:0.68623\n",
      "[54]\ttrain-auc:0.99201\teval-auc:0.68613\n",
      "[55]\ttrain-auc:0.99240\teval-auc:0.68458\n",
      "[56]\ttrain-auc:0.99265\teval-auc:0.68417\n",
      "[57]\ttrain-auc:0.99343\teval-auc:0.68463\n",
      "[58]\ttrain-auc:0.99384\teval-auc:0.68426\n",
      "[59]\ttrain-auc:0.99449\teval-auc:0.68374\n",
      "[60]\ttrain-auc:0.99471\teval-auc:0.68289\n",
      "[61]\ttrain-auc:0.99510\teval-auc:0.68380\n",
      "[62]\ttrain-auc:0.99569\teval-auc:0.68420\n",
      "[63]\ttrain-auc:0.99620\teval-auc:0.68456\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(params, dtrain, num_rounds, watchlist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03cccea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7353\n",
      "Test AUC: 0.6846\n"
     ]
    }
   ],
   "source": [
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bc7c6",
   "metadata": {},
   "source": [
    "# 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff7bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seq = 150\n",
    "num_agents = 11\n",
    "use_pressing_intensity = False\n",
    "selected_features_idx = [1, 2, 4, 7]\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "for i in range(len(train_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-90:]\n",
    "    press_intensity = sample['pressing_intensity'][-90:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "            \n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    train_features.append(feature_vector)\n",
    "    train_labels.append(y_tensor.item())\n",
    "\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "for i in range(len(test_dataset)):\n",
    "    sample = test_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-90:]\n",
    "    press_intensity = sample['pressing_intensity'][-90:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    \n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    test_features.append(feature_vector)\n",
    "    test_labels.append(y_tensor.item())\n",
    "\n",
    "X_train = np.array(train_features)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = np.array(test_features)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b82432f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Dataset Distribution Summary\n",
      "========================================\n",
      "Train Set:\n",
      "  Total samples: 11392\n",
      "    Label 0:  9138 samples (80.21%)\n",
      "    Label 1:  2254 samples (19.79%)\n",
      "----------------------------------------\n",
      "Validation Set:\n",
      "  Total samples: 2849\n",
      "    Label 0:  2281 samples (80.06%)\n",
      "    Label 1:   568 samples (19.94%)\n",
      "----------------------------------------\n",
      "Test Set:\n",
      "  Total samples: 1721\n",
      "    Label 0:  1358 samples (78.91%)\n",
      "    Label 1:   363 samples (21.09%)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_dataset_distribution(y_train, y_val, y_test):\n",
    "    def _print_split(name, labels):\n",
    "        total = len(labels)\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        print(f\"{name} Set:\")\n",
    "        print(f\"  Total samples: {total}\")\n",
    "        for label, count in zip(unique, counts):\n",
    "            percent = (count / total) * 100\n",
    "            print(f\"    Label {label}: {count:>5} samples ({percent:5.2f}%)\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    print(\"\\n📊 Dataset Distribution Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    _print_split(\"Train\", y_train)\n",
    "    _print_split(\"Validation\", y_val)\n",
    "    _print_split(\"Test\", y_test)\n",
    "\n",
    "print_dataset_distribution(y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e48d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost DMatrix objects for train and test sets\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Set XGBoost training parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # binary classification\n",
    "    'eval_metric': 'auc',            # evaluation metric: AUC\n",
    "    'max_depth': 6,                  # maximum depth of trees\n",
    "    'eta': 0.1,                      # learning rate\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Specify the watchlist to evaluate performance on training and test sets during training\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "856ef086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/miniconda/envs/mhl_py311/lib/python3.11/site-packages/xgboost/core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.72404\teval-auc:0.59755\n",
      "[1]\ttrain-auc:0.77449\teval-auc:0.61684\n",
      "[2]\ttrain-auc:0.80143\teval-auc:0.61842\n",
      "[3]\ttrain-auc:0.82563\teval-auc:0.62081\n",
      "[4]\ttrain-auc:0.83993\teval-auc:0.62739\n",
      "[5]\ttrain-auc:0.85611\teval-auc:0.63009\n",
      "[6]\ttrain-auc:0.86313\teval-auc:0.63397\n",
      "[7]\ttrain-auc:0.87409\teval-auc:0.63416\n",
      "[8]\ttrain-auc:0.88935\teval-auc:0.63792\n",
      "[9]\ttrain-auc:0.89944\teval-auc:0.63648\n",
      "[10]\ttrain-auc:0.90767\teval-auc:0.63826\n",
      "[11]\ttrain-auc:0.91626\teval-auc:0.63678\n",
      "[12]\ttrain-auc:0.92196\teval-auc:0.63293\n",
      "[13]\ttrain-auc:0.92891\teval-auc:0.63344\n",
      "[14]\ttrain-auc:0.93481\teval-auc:0.63360\n",
      "[15]\ttrain-auc:0.93753\teval-auc:0.63349\n",
      "[16]\ttrain-auc:0.94254\teval-auc:0.63322\n",
      "[17]\ttrain-auc:0.94739\teval-auc:0.63347\n",
      "[18]\ttrain-auc:0.94938\teval-auc:0.63573\n",
      "[19]\ttrain-auc:0.95371\teval-auc:0.63360\n",
      "[20]\ttrain-auc:0.95596\teval-auc:0.63550\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost model with early stopping on the evaluation set\n",
    "bst = xgb.train(params, dtrain, num_rounds, watchlist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96af079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8027\n",
      "Test AUC: 0.6491\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c5df0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7989\n",
      "Test AUC: 0.6465\n"
     ]
    }
   ],
   "source": [
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb1665e",
   "metadata": {},
   "source": [
    "# 2. SoccerMap / exPress Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96d976f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import os\n",
    "os.chdir('/home/work/MHL/express-v2')\n",
    "import argparse # To accept checkpoint path as argument\n",
    "\n",
    "# Import project modules\n",
    "# import config  # Import static configurations\n",
    "from model import PytorchSoccerMapModel # Import Lightning model\n",
    "from datasets import PressingSequenceDataset, SoccerMapInputDataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08a1fab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from /data/MHL/pressing-intensity/test_dataset.pkl...\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42, workers=True) # Ensure reproducibility\n",
    "\n",
    "DATA_PATH = \"/data/MHL/pressing-intensity\" # Path where pickled datasets are saved\n",
    "test_dataset = SoccerMapInputDataset(os.path.join(DATA_PATH, \"test_dataset.pkl\"))\n",
    "\n",
    "if len(test_dataset) == 0:\n",
    "    print(\"Loaded test dataset is empty. Exiting.\")\n",
    "\n",
    "# Custom collate function to handle potential None values from dataset errors\n",
    "def collate_fn_skip_none(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    if not batch: return None\n",
    "    try: return torch.utils.data.dataloader.default_collate(batch)\n",
    "    except RuntimeError: return None # Skip batch if collation error\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    # collate_fn=collate_fn_skip_none\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45aabfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Train a pressing evaluation model.\")\n",
    "# parser.add_argument(\"--model_type\", type=str, default=\"soccermap\", choices=['soccermap', 'xgboost', 'exPress'], help=\"Path to the model checkpoint (.ckpt) file saved during training.\")\n",
    "# parser.add_argument(\"--root_path\", type=str, default=\"/data/MHL/pressing-intensity\", help=\"Path to the data file.\")\n",
    "parser.add_argument(\"--model_type\", type=str, default=\"soccermap\", choices=['soccermap', 'xgboost', 'exPress'], help=\"Path to the model checkpoint (.ckpt) file saved during training.\")\n",
    "parser.add_argument(\"--root_path\", type=str, default=\"/data/MHL/pressing-intensity\", help=\"Path to the data file.\")\n",
    "parser.add_argument(\"--mode\", type=str, default=\"train\", choices=['train', 'test'], help=\"Mode: 'train' or 'test'.\")\n",
    "parser.add_argument(\"--ckpt_path\", type=str, default=None, help=\"Path to checkpoint file (Required for 'test' mode).\")\n",
    "parser.add_argument(\"--params_path\", type=str, default=\"params.json\", help=\"Path to the JSON containing configurations.\")\n",
    "parser.add_argument(\"--seed\", type=int, default=42, help=\"Seed number.\")\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "args.mode = 'test'\n",
    "args.model_type = \"exPress\"\n",
    "args.ckpt_path = \"/data/MHL/pressing-intensity/checkpoints/exPress-epoch=28-val_loss=0.49.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4dcd43e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations loaded from params.json.\n"
     ]
    }
   ],
   "source": [
    "from components import press\n",
    "\n",
    "\n",
    "component_dict = {\n",
    "                    \"soccermap\": press.SoccerMapComponent,\n",
    "                    \"exPress\": press.exPressComponent,\n",
    "                }\n",
    "\n",
    "exp = component_dict[args.model_type](args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193af97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expressv2",
   "language": "python",
   "name": "expressv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
