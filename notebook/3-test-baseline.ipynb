{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be2b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 07:47:35.320810: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-07 07:47:35.323190: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-07 07:47:35.352304: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-07 07:47:35.352336: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-07 07:47:35.352359: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-07 07:47:35.359186: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "import torch\n",
    "\n",
    "from datasets import PressingSequenceDataset, SoccerMapInputDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ac95b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14241, 1721)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/data/MHL/pressing-intensity\"\n",
    "\n",
    "with open(f\"{data_path}/train_dataset.pkl\", \"rb\") as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "with open(f\"{data_path}/test_dataset.pkl\", \"rb\") as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff0d100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'pressing_intensity', 'label', 'presser_id', 'agent_order'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df18d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features : torch.Size([150, 23, 8])\n",
      "Pressing Intensity : torch.Size([150, 11, 11])\n",
      "Labels : 0\n",
      "Presser ID : 77414\n",
      "Players Order : ['188178', '250079', '250101', '250102', '500133', '500140', '500141', '500142', '62365', '62386', '77414', '187259', '343587', '408792', '500113', '500115', '500116', '500117', '500118', '500121', '500502', '83615', 'ball']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features : {sample['features'].shape}\")\n",
    "print(f\"Pressing Intensity : {sample['pressing_intensity'].shape}\")\n",
    "print(f\"Labels : {sample['label']}\")\n",
    "print(f\"Presser ID : {sample['presser_id']}\")\n",
    "print(f\"Players Order : {sample['agent_order']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5fbfc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([150, 23, 8]), torch.Size([150, 11, 11]), tensor(0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = sample['features']\n",
    "press_intensity = sample['pressing_intensity']\n",
    "y_tensor = sample['label']\n",
    "x_tensor.shape, press_intensity.shape, y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bc7c6",
   "metadata": {},
   "source": [
    "# 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7bfa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "num_seq = 150\n",
    "num_agents = 11\n",
    "use_pressing_intensity = False\n",
    "selected_features_idx = [1, 2, 4, 7]\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "for i in range(len(train_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-90:]\n",
    "    press_intensity = sample['pressing_intensity'][-90:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "            \n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    train_features.append(feature_vector)\n",
    "    train_labels.append(y_tensor.item())\n",
    "\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "for i in range(len(test_dataset)):\n",
    "    sample = test_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-90:]\n",
    "    press_intensity = sample['pressing_intensity'][-90:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    \n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    test_features.append(feature_vector)\n",
    "    test_labels.append(y_tensor.item())\n",
    "\n",
    "X_train = np.array(train_features)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = np.array(test_features)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b82432f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Dataset Distribution Summary\n",
      "========================================\n",
      "Train Set:\n",
      "  Total samples: 11392\n",
      "    Label 0:  9147 samples (80.29%)\n",
      "    Label 1:  2245 samples (19.71%)\n",
      "----------------------------------------\n",
      "Validation Set:\n",
      "  Total samples: 2849\n",
      "    Label 0:  2286 samples (80.24%)\n",
      "    Label 1:   563 samples (19.76%)\n",
      "----------------------------------------\n",
      "Test Set:\n",
      "  Total samples: 1721\n",
      "    Label 0:  1359 samples (78.97%)\n",
      "    Label 1:   362 samples (21.03%)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_dataset_distribution(y_train, y_val, y_test):\n",
    "    def _print_split(name, labels):\n",
    "        total = len(labels)\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        print(f\"{name} Set:\")\n",
    "        print(f\"  Total samples: {total}\")\n",
    "        for label, count in zip(unique, counts):\n",
    "            percent = (count / total) * 100\n",
    "            print(f\"    Label {label}: {count:>5} samples ({percent:5.2f}%)\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    print(\"\\nðŸ“Š Dataset Distribution Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    _print_split(\"Train\", y_train)\n",
    "    _print_split(\"Validation\", y_val)\n",
    "    _print_split(\"Test\", y_test)\n",
    "\n",
    "print_dataset_distribution(y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e48d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost DMatrix objects for train and test sets\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Set XGBoost training parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # binary classification\n",
    "    'eval_metric': 'auc',            # evaluation metric: AUC\n",
    "    'max_depth': 6,                  # maximum depth of trees\n",
    "    'eta': 0.1,                      # learning rate\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Specify the watchlist to evaluate performance on training and test sets during training\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "856ef086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/miniconda/envs/mhl_py311/lib/python3.11/site-packages/xgboost/core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.72404\teval-auc:0.59755\n",
      "[1]\ttrain-auc:0.77449\teval-auc:0.61684\n",
      "[2]\ttrain-auc:0.80143\teval-auc:0.61842\n",
      "[3]\ttrain-auc:0.82563\teval-auc:0.62081\n",
      "[4]\ttrain-auc:0.83993\teval-auc:0.62739\n",
      "[5]\ttrain-auc:0.85611\teval-auc:0.63009\n",
      "[6]\ttrain-auc:0.86313\teval-auc:0.63397\n",
      "[7]\ttrain-auc:0.87409\teval-auc:0.63416\n",
      "[8]\ttrain-auc:0.88935\teval-auc:0.63792\n",
      "[9]\ttrain-auc:0.89944\teval-auc:0.63648\n",
      "[10]\ttrain-auc:0.90767\teval-auc:0.63826\n",
      "[11]\ttrain-auc:0.91626\teval-auc:0.63678\n",
      "[12]\ttrain-auc:0.92196\teval-auc:0.63293\n",
      "[13]\ttrain-auc:0.92891\teval-auc:0.63344\n",
      "[14]\ttrain-auc:0.93481\teval-auc:0.63360\n",
      "[15]\ttrain-auc:0.93753\teval-auc:0.63349\n",
      "[16]\ttrain-auc:0.94254\teval-auc:0.63322\n",
      "[17]\ttrain-auc:0.94739\teval-auc:0.63347\n",
      "[18]\ttrain-auc:0.94938\teval-auc:0.63573\n",
      "[19]\ttrain-auc:0.95371\teval-auc:0.63360\n",
      "[20]\ttrain-auc:0.95596\teval-auc:0.63550\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost model with early stopping on the evaluation set\n",
    "bst = xgb.train(params, dtrain, num_rounds, watchlist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96af079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8027\n",
      "Test AUC: 0.6491\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c5df0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7989\n",
      "Test AUC: 0.6465\n"
     ]
    }
   ],
   "source": [
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb1665e",
   "metadata": {},
   "source": [
    "# 2. Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2895b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ToSoccerMapTensor\n",
    "\n",
    "SoccerMapTensor = ToSoccerMapTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "417953f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "sample = train_dataset[i]\n",
    "x_tensor = sample['features']\n",
    "press_intensity = sample['pressing_intensity']\n",
    "y_tensor = sample['label']\n",
    "presser_id = sample['presser_id']\n",
    "agents_order = sample['agent_order']\n",
    "presser_idx = agents_order.index(presser_id)\n",
    "home_team_ids = agents_order[:11]\n",
    "away_team_ids = agents_order[11:22]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3fa9a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 8])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_feat = x_tensor[-1, ...]\n",
    "x_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "41eab5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 23, 8])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3adfc442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 68, 104)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bins, x_bins = (68, 104)\n",
    "num_features = 13\n",
    "nb_prev_actions = 1\n",
    "matrix = np.zeros((num_features * nb_prev_actions, y_bins, x_bins)) # 13, 68, 104\n",
    "# Location of the goal\n",
    "goal_coo = torch.tensor([[52.5, 0]])\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a7bb651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_cell_indexes(self, x: torch.Tensor, y: torch.Tensor):\n",
    "def _get_cell_indexes(x: torch.Tensor, y: torch.Tensor):\n",
    "    # Shift the origin from the pitch center to the bottom-left corner:\n",
    "    #   x: [-52.5, 52.5] -> [0, 105]\n",
    "    #   y: [-34.0,  34.0] -> [0,  68]\n",
    "    x_shifted = x + 52.5\n",
    "    y_shifted = y + 34.0\n",
    "\n",
    "    # Normalize into [0, 1]\n",
    "    x_norm = x_shifted / 105.0\n",
    "    y_norm = y_shifted /  68.0\n",
    "\n",
    "    # Scale to bin coordinates\n",
    "    # x_cont = x_norm * self.x_bins\n",
    "    # y_cont = y_norm * self.y_bins\n",
    "    x_cont = x_norm * x_bins\n",
    "    y_cont = y_norm * y_bins\n",
    "    \n",
    "    # Clamp into valid index range [0, bins-1]\n",
    "    # x_clamped = torch.clamp(x_cont, min=0, max=self.x_bins - 1)\n",
    "    # y_clamped = torch.clamp(y_cont, min=0, max=self.y_bins - 1)\n",
    "    x_clamped = torch.clamp(x_cont, min=0, max=x_bins - 1)\n",
    "    y_clamped = torch.clamp(y_cont, min=0, max=y_bins - 1)\n",
    "\n",
    "    # Convert to integer bin indices\n",
    "    x_bin = x_clamped.to(torch.int64).to(torch.uint8)\n",
    "    y_bin = y_clamped.to(torch.int64).to(torch.uint8)\n",
    "\n",
    "    return x_bin, y_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc347f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "home_indices = slice(0, 11)\n",
    "away_indices = slice(11, 22)\n",
    "\n",
    "if presser_id in home_team_ids:\n",
    "    pressing_indices = home_indices\n",
    "    pressed_indices = away_indices\n",
    "    x_bin_pressing, y_bin_pressing = _get_cell_indexes(x_feat[pressing_indices, :1], x_feat[pressing_indices, 1:2])\n",
    "    x_bin_pressed, y_bin_pressed = _get_cell_indexes(x_feat[pressed_indices, :1], x_feat[pressed_indices, 1:2])\n",
    "elif presser_id in away_team_ids:\n",
    "    pressed_indices = home_indices\n",
    "    pressing_indices = away_indices\n",
    "    x_bin_pressed, y_bin_pressed= _get_cell_indexes(x_feat[pressed_indices, :1], x_feat[pressed_indices, 1:2])\n",
    "    x_bin_pressing, y_bin_pressing = _get_cell_indexes(x_feat[pressing_indices, :1], x_feat[pressing_indices, 1:2])\n",
    "else:\n",
    "    raise ValueError(f\"Invalid presser_id: {presser_id}\")\n",
    "\n",
    "# Ch 1: Locations of pressing teams\n",
    "matrix[0 + i * num_features, y_bin_pressing, x_bin_pressing] = 1\n",
    "\n",
    "# Ch 2: vx of pressing teams\n",
    "matrix[1 + i * num_features, y_bin_pressing, x_bin_pressing] = x_feat[pressing_indices, 2:3]\n",
    "\n",
    "# Ch 3: vy of pressing teams\n",
    "matrix[2 + i * num_features, y_bin_pressing, x_bin_pressing] = x_feat[pressing_indices, 3:4]\n",
    "\n",
    "# CH 4: Locations of pressed teams\n",
    "matrix[3 + i * num_features, y_bin_pressed, x_bin_pressed] = 1\n",
    "\n",
    "# Ch 5: vx of pressed teams\n",
    "matrix[4 + i * num_features, y_bin_pressed, x_bin_pressed] = x_feat[pressed_indices, 2:3]\n",
    "\n",
    "# Ch 6: vy of pressed teams\n",
    "matrix[5 + i * num_features, y_bin_pressed, x_bin_pressed] = x_feat[pressed_indices, 3:4]\n",
    "\n",
    "# CH 7: Distance to ball\n",
    "y_coords = torch.arange(0.5, y_bins, device=x_feat.device) # Shape: [y_bins]\n",
    "x_coords = torch.arange(0.5, x_bins, device=x_feat.device)\n",
    "\n",
    "# Create 2D grid coordinate tensors\n",
    "# 'ij' indexing: yy changes along dim 0, xx changes along dim 1\n",
    "yy, xx = torch.meshgrid(y_coords, x_coords, indexing='ij')\n",
    "# yy shape: [y_bins, x_bins], xx shape: [y_bins, x_bins]\n",
    "\n",
    "x0_ball, y0_ball = _get_cell_indexes(x_feat[22, :1], x_feat[22, 1:2])\n",
    "x0_ball_center = x0_ball.float() + 0.5\n",
    "y0_ball_center = x0_ball.float() + 0.5\n",
    "\n",
    "ball_distance = torch.sqrt((xx - x0_ball_center)**2 + (yy - y0_ball_center)**2)\n",
    "matrix[6 + i * num_features, : , :] = ball_distance.numpy()\n",
    "\n",
    "# CH 8: Distance to goal\n",
    "x0_goal, y0_goal = _get_cell_indexes(goal_coo[:, 0], goal_coo[:, 1])\n",
    "x0_goal_center = x0_goal.float() + 0.5\n",
    "y0_goal_center = y0_goal.float() + 0.5\n",
    "\n",
    "goal_distance = torch.sqrt((xx - x0_goal_center)**2 + (yy - y0_goal_center)**2)\n",
    "matrix[7 + i * num_features, : , :] = goal_distance.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51dc5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CH 9: Cosine of the angle between the ball and goal\n",
    "coords = torch.stack([xx, yy], dim=-1) # Shape: [H, W, 2]\n",
    "goal_coo_bin = torch.tensor([x0_goal_center, y0_goal_center], dtype=torch.float32, device=x_feat.device) # Shape: [2]\n",
    "ball_coo_bin = torch.tensor([x0_ball_center, y0_ball_center], dtype=torch.float32, device=x_feat.device) # Shape: [2]\n",
    "a = goal_coo_bin - coords # Shape: [H, W, 2], vector from cell (i,j) to goal\n",
    "b = ball_coo_bin - coords # Shape: [H, W, 2], vector from cell (i,j) to ball\n",
    "\n",
    "norm_a = torch.linalg.norm(a, dim=-1) # Shape: [H, W]\n",
    "norm_b = torch.linalg.norm(b, dim=-1) # Shape: [H, W]\n",
    "denominator = norm_a * norm_b + 1e-8 # Add epsilon here\n",
    "cosine_angle = torch.sum(a * b, dim=-1) / (norm_a + norm_b + 1e-8)\n",
    "cosine_angle = torch.clamp(cosine_angle, min=-1.0, max=1.0) # Shape: [H, W]\n",
    "matrix[8 + i * num_features, : , :] = cosine_angle.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d03041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CH 10: Sine of the angle between the ball and goal\n",
    "sine_angle = (a[..., 0] * b[..., 1] - a[..., 1] * b[..., 0]) / (norm_a + norm_b + 1e-8)\n",
    "sine_angle = torch.clamp(sine_angle, min=-1.0, max=1.0)\n",
    "matrix[9 + i * num_features, : , :] = sine_angle.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d75ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CH 11: Angle (in radians) to the goal location\n",
    "vector_y = y0_goal_center - coords[..., 1] # Shape: [H, W]\n",
    "vector_x = x0_goal_center - coords[..., 0] # Shape: [H, W]\n",
    "angle_rad = torch.abs(torch.arctan2(vector_y, vector_x))\n",
    "matrix[10 + i * num_features, : , :] = angle_rad.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece39a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CH 12, 13: Cosine, sine angle to the teammates from pressers\n",
    "teammates_idx = [i for i in range(pressing_indices.start, pressing_indices.stop) if i != presser_idx]\n",
    "\n",
    "pos_presser = x_feat[presser_idx, 0:2]           # Ball carrier position [x, y], Shape: [2]\n",
    "v_presser = x_feat[presser_idx, 2:4]            # Ball carrier velocity [vx, vy], Shape: [2] -> ASSUMPTION about indices 2, 3\n",
    "pos_teammates = x_feat[teammates_idx, 0:2]\n",
    "\n",
    "vec_to_teammate = pos_teammates - pos_presser # Shape: [10, 2]\n",
    "norm_v_carrier = torch.linalg.norm(v_presser)        # Scalar magnitude |u|\n",
    "norm_vec_to_tm = torch.linalg.norm(vec_to_teammate, dim=1) # Magnitude |v| for each teammate, Shape: [10]\n",
    "\n",
    "cosine_angle = torch.sum(v_presser.unsqueeze(0) * vec_to_teammate, dim=1) / (norm_v_carrier * norm_vec_to_tm + 1e-8) # Shape: [10]\n",
    "sine_angle = (v_presser[0] * vec_to_teammate[:, 1] - v_presser[1] * vec_to_teammate[:, 0]) / (norm_v_carrier * norm_vec_to_tm + 1e-8)   # Shape: [10]\n",
    "cosine_angle = torch.clamp(cosine_angle, min=-1.0, max=1.0)\n",
    "sine_angle = torch.clamp(sine_angle, min=-1.0, max=1.0)\n",
    "\n",
    "x_bin_tm, y_bin_tm = _get_cell_indexes(pos_teammates[:, 0], pos_teammates[:, 1])\n",
    "matrix[11 + i * num_features, y_bin_tm, x_bin_tm] = cosine_angle.numpy()\n",
    "matrix[12 + i * num_features, y_bin_tm, x_bin_tm] = sine_angle.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9278ac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from /data/MHL/pressing-intensity/train_dataset.pkl...\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/data/MHL/pressing-intensity\" # Path where pickled datasets are saved\n",
    "\n",
    "train_dataset = SoccerMapInputDataset(os.path.join(DATA_PATH, \"train_dataset.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5a2640d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1625, 68, 104])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor, y = train_dataset[0]\n",
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9278ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_dataset_path = os.path.join(DATA_PATH, \"train_dataset.pkl\")\n",
    "\n",
    "with open(pickled_dataset_path, \"rb\") as f:\n",
    "    # Load the dictionary saved by PressingSequenceDataset\n",
    "    loaded_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f721ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47c4e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92bd90e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32 # Adjust based on GPU memory\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 20 # Adjust as needed\n",
    "NUM_WORKERS = 4 # Adjust based on system cores\n",
    "VAL_SPLIT_RATIO = 0.2 # Use 15% of training data for validation\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True if NUM_WORKERS > 0 else False,\n",
    "        # collate_fn=collate_fn_skip_none # Use this if __getitem__ can return None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31dbba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "814c3381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1fc1597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PytorchSoccerMapModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bec4c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITERION = 'bce' # 'bce' or 'focal'\n",
    "CRITERION_PARAMS = {} # Add params like alpha, gamma for FocalLoss if needed\n",
    "\n",
    "optimizer_params = {\n",
    "\"optimizer_params\": {\n",
    "    \"lr\": 1e-4,\n",
    "    \"weight_decay\": 1e-5\n",
    "}\n",
    "}\n",
    "model_config = {\n",
    "\"in_channels\": 125 * 13\n",
    "}\n",
    "\n",
    "model = PytorchSoccerMapModel(model_config=model_config, optimizer_params=optimizer_params)\n",
    "model = model.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a52a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_data\n",
    "x = x.to(\"cuda\")\n",
    "y = y.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5adb0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f506a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7954191",
   "metadata": {},
   "source": [
    "# 3. exPress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83dc643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "from datasets import exPressInputDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca8bf4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from /data/MHL/pressing-intensity/train_dataset.pkl...\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/data/MHL/pressing-intensity\"\n",
    "full_train_dataset = exPressInputDataset(f\"{data_path}/train_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4d8b00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(80.7753), tensor(-56.0759))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_dataset[0]['features'].max(), full_train_dataset[0]['features'].min() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80448c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_tensor = full_train_dataset[0]['features']\n",
    "\n",
    "min_in_tensor = torch.min(torch.min(features_tensor, dim=0).values, dim=0).values\n",
    "max_in_tensor = torch.max(torch.max(features_tensor, dim=0).values, dim=0).values\n",
    "\n",
    "current_min_vals = torch.minimum(current_min_vals, min_in_tensor)\n",
    "current_max_vals = torch.maximum(current_max_vals, max_in_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77a96a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(239.0878), tensor(-194.9801))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_dataset[i]['features'].max(), full_train_dataset[i]['features'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152350ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(full_train_dataset)):\n",
    "    full_train_dataset[i]['features'].max(), full_train_dataset[i]['features'].min()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fea9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = PyGDataLoader(\n",
    "        full_train_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "        # persistent_workers ë“±ì€ PyTorch DataLoaderì™€ ìœ ì‚¬í•˜ê²Œ ì„¤ì • ê°€ëŠ¥\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d600d0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'pressing_intensity', 'label', 'presser_id', 'agent_order'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b67d54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 125, 23, 8]), torch.Size([16, 125, 11, 11]), torch.Size([16]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['features'].shape, data['pressing_intensity'].shape, data['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b3ed3c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, A, F_in = data['features'].shape\n",
    "x_frames = data['features'].view(B * T, A, F_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a530894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "node_embed = nn.Linear(F_in, 64)\n",
    "node_embed = node_embed.to(\"cuda\")\n",
    "x_frames = x_frames.to(\"cuda\")\n",
    "node_features = F.relu(node_embed(x_frames)) # [B*T, A, F_embed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e027b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 23, 64])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57e60098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46000, 64])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_flat = node_features.view(-1, node_features.shape[-1])\n",
    "node_features_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d777346",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = torch.arange(B * T, device=\"cuda\").repeat_interleave(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "888c917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\"\n",
    "agents_indices = torch.arange(A, device=device)\n",
    "edge_index_player = torch.cartesian_prod(agents_indices, agents_indices).t()\n",
    "edge_index_player = edge_index_player[:, edge_index_player[0] != edge_index_player[1]] # Remove self-loops -> [2, 22*21]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9332ee28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_edges_per_graph = edge_index_player.shape[1]\n",
    "num_edges_per_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba67e3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1012000])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_batch = edge_index_player.repeat(1, B * T) + node_offset\n",
    "edge_index_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e4e78ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1012000])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_weight_batch = torch.ones(edge_index_batch.shape[1], device=device)\n",
    "\n",
    "edge_weight_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7bb8f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 23, 64])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d976f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhl_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
