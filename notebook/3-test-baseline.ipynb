{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6be2b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "import torch\n",
    "\n",
    "from datasets import PressingSequenceDataset, SoccerMapInputDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ac95b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6568, 601, 655)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/data/MHL/pressing-intensity-feat\"\n",
    "\n",
    "with open(f\"{data_path}/train_dataset.pkl\", \"rb\") as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "with open(f\"{data_path}/valid_dataset.pkl\", \"rb\") as f:\n",
    "    valid_dataset = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(f\"{data_path}/test_dataset.pkl\", \"rb\") as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "len(train_dataset),len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ff0d100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'pressing_intensity', 'label', 'pressed_id', 'presser_id', 'agent_order', 'match_info'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df18d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features : torch.Size([2, 23, 18])\n",
      "Pressing Intensity : torch.Size([2, 11, 11])\n",
      "Labels : 0\n",
      "Presser ID : 77414\n",
      "Players Order : ['188178', '250079', '250101', '250102', '500133', '500140', '500141', '500142', '62365', '62386', '77414', '187259', '343587', '408792', '500113', '500115', '500116', '500117', '500118', '500121', '500502', '83615', 'ball']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features : {sample['features'].shape}\")\n",
    "print(f\"Pressing Intensity : {sample['pressing_intensity'].shape}\")\n",
    "print(f\"Labels : {sample['label']}\")\n",
    "print(f\"Presser ID : {sample['presser_id']}\")\n",
    "print(f\"Players Order : {sample['agent_order']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d291e0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-52.5 ~ 52.5\n",
      "-32.0 ~ 32.0\n",
      "-4.0 ~ 1.0\n",
      "-5.0 ~ 3.0\n",
      "0.0 ~ 5.0\n",
      "-4.0 ~ 5.0\n",
      "-4.0 ~ 5.0\n",
      "0.0 ~ 6.0\n",
      "0.0 ~ 1.0\n",
      "0.0 ~ 1.0\n",
      "21.0 ~ 100.0\n",
      "-1.0 ~ 1.0\n",
      "0.0 ~ 1.0\n",
      "0.0 ~ 52.0\n",
      "-1.0 ~ 1.0\n",
      "-1.0 ~ 1.0\n",
      "-1.0 ~ 1.0\n",
      "-1.0 ~ 1.0\n"
     ]
    }
   ],
   "source": [
    "from config import FEAT_MIN, FEAT_MAX\n",
    "\n",
    "for i in range(18):\n",
    "    print(f\"{FEAT_MIN[i]} ~ {FEAT_MAX[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03cccea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-35.245399475097656 ~ 36.746498107910156\n",
      "-23.04159927368164 ~ 31.23430061340332\n",
      "-3.957848072052002 ~ 1.528892159461975\n",
      "-4.297361373901367 ~ 2.6944620609283447\n",
      "0.4733882546424866 ~ 4.297878265380859\n",
      "-3.3421547412872314 ~ 4.828290939331055\n",
      "-3.5408642292022705 ~ 4.212172985076904\n",
      "0.023648617789149284 ~ 5.198577404022217\n",
      "0.0 ~ 1.0\n",
      "0.0 ~ 1.0\n",
      "15.768238067626953 ~ 87.75919342041016\n",
      "-0.5956571102142334 ~ 0.4275398254394531\n",
      "0.8032388091087341 ~ 0.9998427629470825\n",
      "0.0 ~ 51.872928619384766\n",
      "-0.9545497894287109 ~ 0.9746968150138855\n",
      "-0.9999775290489197 ~ 1.0\n",
      "-0.9782698750495911 ~ 1.0\n",
      "-0.9976794719696045 ~ 0.9850823283195496\n"
     ]
    }
   ],
   "source": [
    "x_tensor_lst = [sample['features'] for sample in train_dataset]\n",
    "x_tensor_lst = torch.cat(x_tensor_lst)\n",
    "feature_cols = ['x', 'y', 'vx', 'vy', 'v', 'ax', 'ay', 'a']\n",
    "\n",
    "for i in range(18):\n",
    "    # print(f\"{feature_cols[i]} : {x_tensor_lst[-1, ...][..., i].min()} ~ {x_tensor_lst[-1, ...][..., i].max()}\")\n",
    "    print(f\"{x_tensor_lst[-1, ...][..., i].min()} ~ {x_tensor_lst[-1, ...][..., i].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1b4feb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-47.30929946899414 ~ 27.947900772094727\n",
      "-26.779399871826172 ~ 24.279199600219727\n",
      "-2.786034345626831 ~ 1.6843657493591309\n",
      "-1.6886903047561646 ~ 4.080182075500488\n",
      "0.12533733248710632 ~ 4.414178371429443\n",
      "-2.033162832260132 ~ 20.059629440307617\n",
      "-32.14739990234375 ~ 2.9072623252868652\n",
      "0.14909246563911438 ~ 13.5\n",
      "0.0 ~ 1.0\n",
      "0.0 ~ 1.0\n",
      "24.691688537597656 ~ 99.8106460571289\n",
      "-0.3865571916103363 ~ 0.3389405906200409\n",
      "0.9222654104232788 ~ 0.9999997019767761\n",
      "0.0 ~ 53.62963104248047\n",
      "0.0 ~ 0.9939579367637634\n",
      "-0.8388556241989136 ~ 1.0\n",
      "0.028892746195197105 ~ 1.0\n",
      "-0.923808753490448 ~ 0.9995825290679932\n"
     ]
    }
   ],
   "source": [
    "x_tensor_lst = [sample['features'] for sample in valid_dataset]\n",
    "x_tensor_lst = torch.cat(x_tensor_lst)\n",
    "feature_cols = ['x', 'y', 'vx', 'vy', 'v', 'ax', 'ay', 'a']\n",
    "\n",
    "for i in range(18):\n",
    "    # print(f\"{feature_cols[i]} : {x_tensor_lst[-1, ...][..., i].min()} ~ {x_tensor_lst[-1, ...][..., i].max()}\")\n",
    "    print(f\"{x_tensor_lst[-1, ...][..., i].min()} ~ {x_tensor_lst[-1, ...][..., i].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "848b0d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-22.494892120361328 ~ 50.170204162597656\n",
      "-33.574310302734375 ~ 15.24506950378418\n",
      "-6.2336344718933105 ~ 1.2372031211853027\n",
      "-5.7715325355529785 ~ 1.795527696609497\n",
      "1.2239831686019897 ~ 6.246331691741943\n",
      "-2.944819688796997 ~ 5.235048770904541\n",
      "-6.547811985015869 ~ 1.806138038635254\n",
      "0.14878597855567932 ~ 6.0\n",
      "0.0 ~ 1.0\n",
      "0.0 ~ 1.0\n",
      "3.920572519302368 ~ 75.00214385986328\n",
      "-0.5290470719337463 ~ 0.9910622239112854\n",
      "0.13340020179748535 ~ 0.9999033212661743\n",
      "0.0 ~ 46.72101593017578\n",
      "-0.9999926090240479 ~ 0.16790957748889923\n",
      "-0.9999999403953552 ~ 1.0\n",
      "0.09680623561143875 ~ 1.0\n",
      "-0.9953032732009888 ~ 0.9049455523490906\n"
     ]
    }
   ],
   "source": [
    "x_tensor_lst = [sample['features'] for sample in test_dataset]\n",
    "x_tensor_lst = torch.cat(x_tensor_lst)\n",
    "feature_cols = ['x', 'y', 'vx', 'vy', 'v', 'ax', 'ay', 'a']\n",
    "\n",
    "for i in range(18):\n",
    "    # print(f\"{feature_cols[i]} : {x_tensor_lst[-1, ...][..., i].min()} ~ {x_tensor_lst[-1, ...][..., i].max()}\")\n",
    "    print(f\"{x_tensor_lst[-1, ...][..., i].min()} ~ {x_tensor_lst[-1, ...][..., i].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bc7c6",
   "metadata": {},
   "source": [
    "# 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5ff7bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seq = 150\n",
    "num_agents = 11\n",
    "use_pressing_intensity = True\n",
    "selected_features_idx = [i for i in range(8)]\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "for i in range(len(train_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-1:]\n",
    "    press_intensity = sample['pressing_intensity'][-1:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "            \n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    train_features.append(feature_vector)\n",
    "    train_labels.append(y_tensor.item())\n",
    "\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "for i in range(len(test_dataset)):\n",
    "    sample = test_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-1:]\n",
    "    press_intensity = sample['pressing_intensity'][-1:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    \n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    test_features.append(feature_vector)\n",
    "    test_labels.append(y_tensor.item())\n",
    "\n",
    "X_train = np.array(train_features)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = np.array(test_features)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b82432f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Dataset Distribution Summary\n",
      "========================================\n",
      "Train Set:\n",
      "  Total samples: 5573\n",
      "    Label 0:  4003 samples (71.83%)\n",
      "    Label 1:  1570 samples (28.17%)\n",
      "----------------------------------------\n",
      "Validation Set:\n",
      "  Total samples: 1394\n",
      "    Label 0:  1029 samples (73.82%)\n",
      "    Label 1:   365 samples (26.18%)\n",
      "----------------------------------------\n",
      "Test Set:\n",
      "  Total samples: 867\n",
      "    Label 0:   640 samples (73.82%)\n",
      "    Label 1:   227 samples (26.18%)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_dataset_distribution(y_train, y_val, y_test):\n",
    "    def _print_split(name, labels):\n",
    "        total = len(labels)\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        print(f\"{name} Set:\")\n",
    "        print(f\"  Total samples: {total}\")\n",
    "        for label, count in zip(unique, counts):\n",
    "            percent = (count / total) * 100\n",
    "            print(f\"    Label {label}: {count:>5} samples ({percent:5.2f}%)\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    print(\"\\nüìä Dataset Distribution Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    _print_split(\"Train\", y_train)\n",
    "    _print_split(\"Validation\", y_val)\n",
    "    _print_split(\"Test\", y_test)\n",
    "\n",
    "print_dataset_distribution(y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8e48d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost DMatrix objects for train and test sets\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Set XGBoost training parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # binary classification\n",
    "    'eval_metric': 'auc',            # evaluation metric: AUC\n",
    "    'max_depth': 6,                  # maximum depth of trees\n",
    "    'eta': 0.1,                      # learning rate\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Specify the watchlist to evaluate performance on training and test sets during training\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "856ef086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/miniconda/envs/mhl_py311/lib/python3.11/site-packages/xgboost/core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.75959\teval-auc:0.61427\n",
      "[1]\ttrain-auc:0.79490\teval-auc:0.62917\n",
      "[2]\ttrain-auc:0.82032\teval-auc:0.64981\n",
      "[3]\ttrain-auc:0.83279\teval-auc:0.65480\n",
      "[4]\ttrain-auc:0.84991\teval-auc:0.65820\n",
      "[5]\ttrain-auc:0.86352\teval-auc:0.66439\n",
      "[6]\ttrain-auc:0.87259\teval-auc:0.66480\n",
      "[7]\ttrain-auc:0.87885\teval-auc:0.66355\n",
      "[8]\ttrain-auc:0.88916\teval-auc:0.66851\n",
      "[9]\ttrain-auc:0.89755\teval-auc:0.66977\n",
      "[10]\ttrain-auc:0.90254\teval-auc:0.67374\n",
      "[11]\ttrain-auc:0.91078\teval-auc:0.67134\n",
      "[12]\ttrain-auc:0.91646\teval-auc:0.67048\n",
      "[13]\ttrain-auc:0.92399\teval-auc:0.67064\n",
      "[14]\ttrain-auc:0.92672\teval-auc:0.67047\n",
      "[15]\ttrain-auc:0.93116\teval-auc:0.67298\n",
      "[16]\ttrain-auc:0.93318\teval-auc:0.67497\n",
      "[17]\ttrain-auc:0.93773\teval-auc:0.67577\n",
      "[18]\ttrain-auc:0.94166\teval-auc:0.67500\n",
      "[19]\ttrain-auc:0.94384\teval-auc:0.67588\n",
      "[20]\ttrain-auc:0.94658\teval-auc:0.67564\n",
      "[21]\ttrain-auc:0.94912\teval-auc:0.67658\n",
      "[22]\ttrain-auc:0.95171\teval-auc:0.67768\n",
      "[23]\ttrain-auc:0.95417\teval-auc:0.67648\n",
      "[24]\ttrain-auc:0.95753\teval-auc:0.67740\n",
      "[25]\ttrain-auc:0.95902\teval-auc:0.67896\n",
      "[26]\ttrain-auc:0.96092\teval-auc:0.67626\n",
      "[27]\ttrain-auc:0.96314\teval-auc:0.67798\n",
      "[28]\ttrain-auc:0.96438\teval-auc:0.67823\n",
      "[29]\ttrain-auc:0.96746\teval-auc:0.67843\n",
      "[30]\ttrain-auc:0.97004\teval-auc:0.67799\n",
      "[31]\ttrain-auc:0.97090\teval-auc:0.67850\n",
      "[32]\ttrain-auc:0.97182\teval-auc:0.67738\n",
      "[33]\ttrain-auc:0.97307\teval-auc:0.67579\n",
      "[34]\ttrain-auc:0.97364\teval-auc:0.67586\n",
      "[35]\ttrain-auc:0.97487\teval-auc:0.67534\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost model with early stopping on the evaluation set\n",
    "bst = xgb.train(params, dtrain, num_rounds, watchlist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d32f179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7453\n",
      "Test AUC: 0.6730\n"
     ]
    }
   ],
   "source": [
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cca0c45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7475\n",
      "Test AUC: 0.6753\n"
     ]
    }
   ],
   "source": [
    "# W/ Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb1665e",
   "metadata": {},
   "source": [
    "# 2. SoccerMap / exPress Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59cea614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import exPressInputDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7732b647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from /data/MHL/pressing-intensity-feat/train_dataset.pkl...\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/data/MHL/pressing-intensity-feat\"\n",
    "train_dataset = exPressInputDataset(f\"{data_path}/train_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83f2754c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'pressing_intensity', 'label', 'pressed_id', 'presser_id', 'agent_order', 'match_info'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def custom_temporal_collate(batch):\n",
    "    \"\"\"\n",
    "    Í∞ÄÎ≥Ä Í∏∏Ïù¥Ïùò ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞Î•º Ìè¨Ìï®Ìïú Î∞∞ÏπòÎ•º Ï≤òÎ¶¨ÌïòÎäî collate_fn.\n",
    "    \n",
    "    Args:\n",
    "        batch (list): DatasetÏùò __getitem__Ïù¥ Î∞òÌôòÌïòÎäî ÎîïÏÖîÎÑàÎ¶¨Îì§Ïùò Î¶¨Ïä§Ìä∏.\n",
    "                      Ïòà: [{'features': [T1,A,F], ...}, {'features': [T2,A,F], ...}]\n",
    "    \"\"\"\n",
    "    # 1. Î∞∞Ïπò ÎÇ¥Ïùò Îç∞Ïù¥ÌÑ∞Îì§ÏùÑ ÌÇ§(key)Î≥ÑÎ°ú Î∂ÑÎ¶¨ÌïòÏó¨ Í∞ÅÍ∞ÅÏùò Î¶¨Ïä§Ìä∏Ïóê Îã¥ÏäµÎãàÎã§.\n",
    "    features_list = [item['features'] for item in batch]\n",
    "    intensity_list = [item['pressing_intensity'] for item in batch]\n",
    "    labels_list = [item['label'] for item in batch]\n",
    "    \n",
    "    # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞\n",
    "    pressed_id_list = [item['pressed_id'] for item in batch]\n",
    "    presser_id_list = [item['presser_id'] for item in batch]\n",
    "    agent_order_list = [item['agent_order'] for item in batch]\n",
    "    match_info_list = [item['match_info'] for item in batch]\n",
    "\n",
    "     # Ìå®Îî© Ï†Ñ, Í∞Å ÏãúÌÄÄÏä§Ïùò Ïã§Ï†ú Í∏∏Ïù¥Î•º Ï†ÄÏû•Ìï©ÎãàÎã§.\n",
    "    seq_lengths = torch.tensor([f.shape[0] for f in features_list], dtype=torch.long)\n",
    "    \n",
    "    # 2. torch.nn.utils.rnn.pad_sequenceÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÏãúÌÄÄÏä§ Îç∞Ïù¥ÌÑ∞Îì§ÏùÑ Ìå®Îî©Ìï©ÎãàÎã§.\n",
    "    #    batch_first=TrueÎäî Í≤∞Í≥º ÌÖêÏÑúÏùò Ï≤´ Î≤àÏß∏ Ï∞®ÏõêÏù¥ Î∞∞Ïπò ÌÅ¨Í∏∞Í∞Ä ÎêòÎèÑÎ°ù Ìï©ÎãàÎã§.\n",
    "    #    [B, max_T, A, F] ÌòïÌÉúÍ∞Ä Îê©ÎãàÎã§.\n",
    "    padded_features = pad_sequence(features_list, batch_first=True, padding_value=0.0)\n",
    "    \n",
    "    # pressing_intensityÎèÑ ÎèôÏùºÌïòÍ≤å Ìå®Îî©Ìï©ÎãàÎã§.\n",
    "    # [B, max_T, 11, 11] ÌòïÌÉúÍ∞Ä Îê©ÎãàÎã§.\n",
    "    padded_intensities = pad_sequence(intensity_list, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    # 3. ÌÅ¨Í∏∞Í∞Ä Í≥†Ï†ïÎêú ÌÖêÏÑú Îç∞Ïù¥ÌÑ∞Îì§ÏùÄ torch.stackÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Î¨∂ÏäµÎãàÎã§.\n",
    "    labels = torch.stack(labels_list)\n",
    "\n",
    "    # 4. ÏµúÏ¢ÖÏ†ÅÏúºÎ°ú, Ï≤òÎ¶¨Îêú Îç∞Ïù¥ÌÑ∞Îì§ÏùÑ Îã¥ÏùÄ ÎîïÏÖîÎÑàÎ¶¨Î•º Î∞òÌôòÌï©ÎãàÎã§.\n",
    "    return {\n",
    "        'features': padded_features,           # Ìå®Îî©Îêú ÌÖêÏÑú\n",
    "        'pressing_intensity': padded_intensities, # Ìå®Îî©Îêú ÌÖêÏÑú\n",
    "        'label': labels,           \n",
    "        'seq_lengths': seq_lengths,           # Î∞∞ÏπòÎêú ÌÖêÏÑú\n",
    "        'agent_order': agent_order_list,      # ÌååÏù¥Ïç¨ Î¶¨Ïä§Ìä∏\n",
    "        'presser_id': presser_id_list,        # ÌååÏù¥Ïç¨ Î¶¨Ïä§Ìä∏\n",
    "        'pressed_id': pressed_id_list,        # ÌååÏù¥Ïç¨ Î¶¨Ïä§Ìä∏\n",
    "        'match_info': match_info_list         # ÌååÏù¥Ïç¨ Î¶¨Ïä§Ìä∏\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5f775f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_temporal_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46f0bb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 7, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 6, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 3, 23, 18])\n",
      "torch.Size([16, 4, 23, 18])\n",
      "torch.Size([16, 5, 23, 18])\n",
      "torch.Size([14, 4, 23, 18])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch['features'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e2bb52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "A = 23\n",
    "W = torch.zeros((A, A))\n",
    "\n",
    "avg_press = train_dataset[0]['pressing_intensity'][0, ...]\n",
    "P, O = avg_press.size(0), avg_press.size(1) # P: number of players, O: number of opponents\n",
    "\n",
    "W[:P, P:P+O] = avg_press\n",
    "W[P:P+O, :P] = avg_press.t()\n",
    "\n",
    "# ball (last node) edges remain zeros\n",
    "adj = torch.ones((A, A)) - torch.eye(A)\n",
    "edge_index, _ = dense_to_sparse(adj)\n",
    "edge_attr = W[edge_index[0], edge_index[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b5539967",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = train_dataset[0]['features'][0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b34b5b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_nodes, dest_nodes = edge_index[0], edge_index[1]\n",
    "pos_source = feats[source_nodes, :2]\n",
    "pos_dest = feats[dest_nodes, :2]\n",
    "edge_distances = torch.linalg.norm(pos_source - pos_dest, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "be2f8a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_is_home = source_nodes < 11\n",
    "dest_is_home = dest_nodes < 11\n",
    "source_is_away = (source_nodes >= 11) & (source_nodes < 22)\n",
    "dest_is_away = (dest_nodes >= 11) & (dest_nodes < 22)\n",
    "\n",
    "# Í∞ôÏùÄ ÌåÄÏù∏ Í≤ΩÏö∞: (Îëò Îã§ ÌôàÌåÄ) ÎòêÎäî (Îëò Îã§ ÏõêÏ†ïÌåÄ)\n",
    "is_same = (source_is_home & dest_is_home) | (source_is_away & dest_is_away)\n",
    "edge_same_team = is_same.float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ad6069f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attr = torch.cat([edge_distances, edge_same_team, edge_attr.unsqueeze(1)], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9b35cf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([506])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c248e6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([506, 1])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cc0406fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([506])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1aa3af70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'pressing_intensity', 'label', 'pressed_id', 'presser_id', 'agent_order', 'match_info'])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ff661a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5d3fe8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_shape = []\n",
    "press_shape = []\n",
    "for batch in train_loader:\n",
    "    feat_shape.append(batch['features'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96d976f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import os\n",
    "os.chdir('/home/work/MHL/express-v2')\n",
    "import argparse # To accept checkpoint path as argument\n",
    "\n",
    "# Import project modules\n",
    "# import config  # Import static configurations\n",
    "from model import PytorchSoccerMapModel # Import Lightning model\n",
    "from datasets import PressingSequenceDataset, SoccerMapInputDataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08a1fab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from /data/MHL/pressing-intensity/test_dataset.pkl...\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42, workers=True) # Ensure reproducibility\n",
    "\n",
    "DATA_PATH = \"/data/MHL/pressing-intensity\" # Path where pickled datasets are saved\n",
    "test_dataset = SoccerMapInputDataset(os.path.join(DATA_PATH, \"test_dataset.pkl\"))\n",
    "\n",
    "if len(test_dataset) == 0:\n",
    "    print(\"Loaded test dataset is empty. Exiting.\")\n",
    "\n",
    "# Custom collate function to handle potential None values from dataset errors\n",
    "def collate_fn_skip_none(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    if not batch: return None\n",
    "    try: return torch.utils.data.dataloader.default_collate(batch)\n",
    "    except RuntimeError: return None # Skip batch if collation error\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    # collate_fn=collate_fn_skip_none\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45aabfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Train a pressing evaluation model.\")\n",
    "# parser.add_argument(\"--model_type\", type=str, default=\"soccermap\", choices=['soccermap', 'xgboost', 'exPress'], help=\"Path to the model checkpoint (.ckpt) file saved during training.\")\n",
    "# parser.add_argument(\"--root_path\", type=str, default=\"/data/MHL/pressing-intensity\", help=\"Path to the data file.\")\n",
    "parser.add_argument(\"--model_type\", type=str, default=\"soccermap\", choices=['soccermap', 'xgboost', 'exPress'], help=\"Path to the model checkpoint (.ckpt) file saved during training.\")\n",
    "parser.add_argument(\"--root_path\", type=str, default=\"/data/MHL/pressing-intensity\", help=\"Path to the data file.\")\n",
    "parser.add_argument(\"--mode\", type=str, default=\"train\", choices=['train', 'test'], help=\"Mode: 'train' or 'test'.\")\n",
    "parser.add_argument(\"--ckpt_path\", type=str, default=None, help=\"Path to checkpoint file (Required for 'test' mode).\")\n",
    "parser.add_argument(\"--params_path\", type=str, default=\"params.json\", help=\"Path to the JSON containing configurations.\")\n",
    "parser.add_argument(\"--seed\", type=int, default=42, help=\"Seed number.\")\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "args.mode = 'test'\n",
    "args.model_type = \"exPress\"\n",
    "args.ckpt_path = \"/data/MHL/pressing-intensity/checkpoints/exPress-epoch=28-val_loss=0.49.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4dcd43e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations loaded from params.json.\n"
     ]
    }
   ],
   "source": [
    "from components import press\n",
    "\n",
    "\n",
    "component_dict = {\n",
    "                    \"soccermap\": press.SoccerMapComponent,\n",
    "                    \"exPress\": press.exPressComponent,\n",
    "                }\n",
    "\n",
    "exp = component_dict[args.model_type](args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193af97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhl_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
