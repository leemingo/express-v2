{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be2b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 10:39:09.238107: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-14 10:39:09.238156: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-14 10:39:09.238183: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-14 10:39:09.245451: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-14 10:39:09.954704: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/exPress/express-v2\n"
     ]
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import PressingSequenceDataset, SoccerMapInputDataset\n",
    "import config as C\n",
    "import features as F\n",
    "from bisect import bisect_right\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31019cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6569, 598, 637)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/home/exPress/express-v2/data/bepro/pressing_intensity\"\n",
    "\n",
    "with open(f\"{data_path}/train_dataset.pkl\", \"rb\") as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "with open(f\"{data_path}/valid_dataset.pkl\", \"rb\") as f:\n",
    "    valid_dataset = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(f\"{data_path}/test_dataset.pkl\", \"rb\") as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0669211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Game IDs: (30, ['126293', '126298', '126306', '126309', '126315', '126325', '126332', '126341', '126348', '126350', '126356', '126364', '126367', '126378', '126380', '126386', '126391', '126401', '126408', '126411', '126418', '126424', '126429', '126433', '126444', '126448', '126455', '126458', '126466', '126473'])\n",
      "Valid Game IDs: (3, ['126476', '153364', '153373'])\n",
      "Test Game IDs: (3, ['153379', '153385', '153387'])\n"
     ]
    }
   ],
   "source": [
    "def check_game_ids(dataset):\n",
    "    game_ids = set()\n",
    "    for idx, sample in enumerate(dataset):\n",
    "        game_id, _, _ = sample['match_info'].split('-')\n",
    "        game_ids.add(game_id)\n",
    "    return len(game_ids), sorted(game_ids)\n",
    "\n",
    "print(\"Train Game IDs:\", check_game_ids(train_dataset))\n",
    "print(\"Valid Game IDs:\", check_game_ids(valid_dataset))\n",
    "print(\"Test Game IDs:\", check_game_ids(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4423e5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features : torch.Size([3, 23, 18])\n",
      "Pressing Intensity : torch.Size([3, 11, 11])\n",
      "Labels : 0\n",
      "Presser ID : 248890\n",
      "Players Order : ['250079', '250101', '250102', '500133', '500135', '500139', '500140', '500141', '62365', '62386', '77414', '139210', '143410', '161110', '187326', '188266', '248890', '344466', '344467', '62009', '62038', '77579', 'ball']\n",
      "match info : 126285-1.0-522\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "\n",
    "print(f\"Features : {sample['features'].shape}\")\n",
    "print(f\"Pressing Intensity : {sample['pressing_intensity'].shape}\")\n",
    "print(f\"Labels : {sample['label']}\")\n",
    "print(f\"Presser ID : {sample['presser_id']}\")\n",
    "print(f\"Players Order : {sample['agent_order']}\")\n",
    "print(f\"match info : {sample['match_info']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39086842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def compute_second_half_offset(tracking_df):\n",
    "\n",
    "    df = tracking_df.copy()\n",
    "    df['timestamp'] = pd.to_timedelta(df['timestamp'])\n",
    "\n",
    "    # ì „ë°˜ ì¢…ë£Œ ì‹œì \n",
    "    first_half_end = df[df['period_id'] == 1]['timestamp'].max()\n",
    "\n",
    "    # í›„ë°˜ ì‹œì‘ ì‹œì \n",
    "    second_half_start = df[df['period_id'] == 2]['timestamp'].min()\n",
    "\n",
    "    # offset ê³„ì‚° (í›„ë°˜ timestampì— ë”í•  ì‹œê°„)\n",
    "    offset = (first_half_end - second_half_start).total_seconds()\n",
    "\n",
    "    return offset\n",
    "\n",
    "def update_features(dataset, feature_list, processed_data_path, cache_dir=\"feature_cache\"):\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    game_sample_map = defaultdict(list)\n",
    "\n",
    "    # 1. game_id ê¸°ì¤€ìœ¼ë¡œ ìƒ˜í”Œ ì¸ë±ìŠ¤ì™€ frame_idë¥¼ ëª¨ìŒ\n",
    "    for idx, sample in enumerate(dataset): # dataset.__len__ì— ì˜í•´ ê²°ì •ë˜ëŠ” ê¸¸ì´ë§Œí¼ ë£¨í”„\n",
    "        game_id, _, frame_id_str = sample['match_info'].split('-')\n",
    "        frame_id = int(frame_id_str)\n",
    "        game_sample_map[game_id].append((idx, frame_id))\n",
    "\n",
    "    # 2. game_id ë‹¨ìœ„ë¡œ ëª¨ë“  ì²˜ë¦¬ (ë°ì´í„° ë¡œë“œ, timestamp ë§¤í•‘, í”¼ì²˜ ê³„ì‚°, ë°ì´í„°ì…‹ ì—…ë°ì´íŠ¸)\n",
    "    for game_id, frame_infos_for_game in game_sample_map.items():\n",
    "        print(f\"\\n--- Processing Game ID: {game_id} ---\")\n",
    "\n",
    "        # 2-1. í•´ë‹¹ game_idì˜ ë°ì´í„° ë¡œë“œ\n",
    "        tracking_df = pd.read_csv(os.path.join(processed_data_path, game_id, f\"{game_id}_traces.csv\"))\n",
    "        events_df = pd.read_csv(os.path.join(processed_data_path, game_id, f\"{game_id}_merged.csv\"))\n",
    "        teams_df = pd.read_csv(os.path.join(processed_data_path, game_id, f\"{game_id}_teams.csv\"))\n",
    "        events_df = events_df.sort_values(\"timestamp\")\n",
    "        events_df[\"time_seconds\"] = pd.to_numeric(events_df[\"time_seconds\"], errors=\"coerce\")\n",
    "\n",
    "        offset = compute_second_half_offset(tracking_df)\n",
    "\n",
    "        # 2-2. frame_id -> timestamp ë§¤í•‘ (ìŠ¤ì½”í”„ê°€ ì´ ë£¨í”„ ë‚´ë¶€ë¡œ ì œí•œë¨)\n",
    "        frame_id_to_ts = {}\n",
    "        for fid in [fid for _, fid in frame_infos_for_game]: # í˜„ì¬ game_idì— í•´ë‹¹í•˜ëŠ” fidë“¤ë§Œ ì‚¬ìš©\n",
    "            row = tracking_df[tracking_df[\"frame_id\"] == fid]\n",
    "            if not row.empty:\n",
    "                ts = pd.to_timedelta(row.iloc[0][\"timestamp\"]).total_seconds()\n",
    "                if row.iloc[0][\"period_id\"] == 2:\n",
    "                    ts += offset\n",
    "                frame_id_to_ts[fid] = ts\n",
    "\n",
    "        # 2-3. í”¼ì²˜ ê³„ì‚° ë° ë²„í¼ë§ (í˜„ì¬ game_idì— ì†í•˜ëŠ” ìƒ˜í”Œë“¤ë§Œ ì²˜ë¦¬)\n",
    "        # ì´ ë²„í¼ëŠ” í˜„ì¬ game_id ë‚´ì—ì„œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "        current_game_sample_feature_buffer = defaultdict(list) \n",
    "\n",
    "        for feature_name in feature_list: # ê° í”¼ì²˜ ì´ë¦„ì— ëŒ€í•´\n",
    "            func = getattr(F, feature_name)\n",
    "            game_feature_dir = os.path.join(cache_dir, game_id)\n",
    "            os.makedirs(game_feature_dir, exist_ok=True)\n",
    "\n",
    "            cache_path = os.path.join(cache_dir, game_id, f\"{game_id}_{feature_name}.npy\")\n",
    "            feature_cache = None\n",
    "            \n",
    "            if os.path.exists(cache_path):                \n",
    "                feature_cache = np.load(cache_path, allow_pickle=True).item()  # dict: sample_idx -> (B, 1)\n",
    "            else:\n",
    "                feature_cache = {}\n",
    "\n",
    "            feature_updated = False\n",
    "\n",
    "            # í˜„ì¬ game_idì˜ ìƒ˜í”Œë“¤ë§Œ ìˆœíšŒ\n",
    "            for sample_idx, fid in frame_infos_for_game: \n",
    "                if fid not in frame_id_to_ts:\n",
    "                    print(f\"WARN: Skipping sample_idx {sample_idx}, fid {fid} for game {game_id} as timestamp not found.\")\n",
    "                    continue\n",
    "                ts = frame_id_to_ts[fid]\n",
    "                current_sample_data_dict = dataset[sample_idx] \n",
    "                feature_tensor = current_sample_data_dict['features'] \n",
    "                B, N, D = feature_tensor.shape\n",
    "\n",
    "                if sample_idx in feature_cache:\n",
    "                    feat_val = feature_cache[sample_idx]\n",
    "                else:                \n",
    "                    full_past_events = events_df[events_df[\"time_seconds\"] < ts].sort_values(\"time_seconds\", ascending=False)\n",
    "                    past_events = full_past_events.head(B)\n",
    "\n",
    "                    if past_events.empty:\n",
    "                        feat_val = np.full((B, 1), np.nan, dtype=np.float32)\n",
    "                    else:\n",
    "                        if feature_name == \"sum_pitch_control\":\n",
    "                            feat_val = func(past_events, teams_df)                    \n",
    "                        elif feature_name in [\"time_since_last_opponent_action\", \"cumul_goal_att\", \"cumul_goal_def\", \"goaldiff\"]:\n",
    "                            feat_val = func(past_events, events_df)\n",
    "                        else:\n",
    "                            feat_val = func(past_events)\n",
    "                    \n",
    "                        if isinstance(feat_val, pd.DataFrame):\n",
    "                            feat_val = feat_val.values.astype(np.float32)\n",
    "                        elif isinstance(feat_val, np.ndarray):\n",
    "                            feat_val = feat_val.astype(np.float32)\n",
    "                    \n",
    "                        if feat_val.ndim == 1:\n",
    "                            feat_val = feat_val.reshape(-1, 1) # í•­ìƒ (B, 1) ë˜ëŠ” (ì´ë²¤íŠ¸ ìˆ˜, 1) í˜•íƒœë¡œ ìœ ì§€\n",
    "\n",
    "                    feature_cache[sample_idx] = feat_val\n",
    "                    feature_updated = True\n",
    "\n",
    "                new_feature_tensor = torch.tensor(feat_val, dtype=torch.float32).unsqueeze(1).expand(-1, N, -1) # (B, N, F)\n",
    "                current_game_sample_feature_buffer[sample_idx].append(new_feature_tensor)\n",
    "                # print(f\"DEBUG: New feature '{feature_name}' for sample {sample_idx} shape: {new_feature_tensor.shape}\", flush=True)\n",
    "            \n",
    "            if feature_updated:\n",
    "                np.save(cache_path, feature_cache)\n",
    "                print(f\"Saved cached feature for {feature_name} (game {game_id})\")\n",
    "\n",
    "        # 2-4. í˜„ì¬ game_idì— ëŒ€í•œ ëª¨ë“  í”¼ì²˜ ê³„ì‚°ì´ ëë‚˜ë©´, datasetì— ìµœì¢…ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
    "        for sample_idx, new_feats_for_sample in current_game_sample_feature_buffer.items():\n",
    "            # datasetì—ì„œ í•´ë‹¹ sample_idxì˜ í˜„ì¬ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "            current_sample_data_dict = dataset[sample_idx] # __getitem__ í˜¸ì¶œ\n",
    "\n",
    "            original_feature_tensor = current_sample_data_dict['features'] # í˜„ì¬ features í…ì„œ\n",
    "\n",
    "            # ìƒˆë¡­ê²Œ ì¶”ê°€ë  ëª¨ë“  í”¼ì²˜ í…ì„œë“¤ì„ dim=-1ì„ ê¸°ì¤€ìœ¼ë¡œ íš¡ìœ¼ë¡œ í•©ì¹©ë‹ˆë‹¤.\n",
    "            concat_all_new_features = torch.cat(new_feats_for_sample, dim=-1) \n",
    "\n",
    "            # ê¸°ì¡´ í”¼ì²˜ í…ì„œì™€ ìƒˆë¡œ í•©ì³ì§„ í”¼ì²˜ í…ì„œë¥¼ ë‹¤ì‹œ dim=-1ì„ ê¸°ì¤€ìœ¼ë¡œ í•©ì¹©ë‹ˆë‹¤.\n",
    "            final_concatenated_feature_tensor = torch.cat([original_feature_tensor, concat_all_new_features], dim=-1)\n",
    "\n",
    "            # ì—…ë°ì´íŠ¸ëœ features í…ì„œë¥¼ ë”•ì…”ë„ˆë¦¬ì— ë‹¤ì‹œ í• ë‹¹í•©ë‹ˆë‹¤.\n",
    "            current_sample_data_dict['features'] = final_concatenated_feature_tensor\n",
    "\n",
    "            # datasetì˜ __setitem__ì„ í˜¸ì¶œí•˜ì—¬ ë°ì´í„°ì…‹ ë‚´ë¶€ì˜ ì‹¤ì œ ë°ì´í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "            # ì´ ë¼ì¸ì´ ì‹¤í–‰ë  ë•Œ __setitem__ì´ ì—†ìœ¼ë©´ TypeErrorê°€ ë°œìƒí•˜ê³ ,\n",
    "            # __setitem__ì´ ì˜ëª» êµ¬í˜„ë˜ë©´ IndexErrorê°€ ë°œìƒí•©ë‹ˆë‹¤.\n",
    "            dataset[sample_idx] = current_sample_data_dict \n",
    "\n",
    "            # print(f\"DEBUG: Final shape for sample {sample_idx} in game {game_id}: {dataset[sample_idx]['features'].shape}\", flush=True)\n",
    "            # ì´ printëŠ” __getitem__ì´ í˜¸ì¶œë˜ì–´ ë°˜í™˜ëœ ê°’ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ce2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def update_features(dataset, feature_list, processed_data_path, cache_dir=\"feature_cache\"):\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    game_sample_map = defaultdict(list)\n",
    "\n",
    "    # 1. game_id ê¸°ì¤€ìœ¼ë¡œ ìƒ˜í”Œ ì¸ë±ìŠ¤ì™€ frame_idë¥¼ ëª¨ìŒ\n",
    "    for idx, sample in enumerate(dataset): # dataset.__len__ì— ì˜í•´ ê²°ì •ë˜ëŠ” ê¸¸ì´ë§Œí¼ ë£¨í”„\n",
    "        game_id, period_id_str, frame_id_str = sample['match_info'].split('-')\n",
    "        frame_id = int(frame_id_str)\n",
    "        period_id = int(float(period_id_str))\n",
    "        game_sample_map[game_id].append((idx, period_id, frame_id))\n",
    "\n",
    "\n",
    "    # 2. game_id ë‹¨ìœ„ë¡œ ëª¨ë“  ì²˜ë¦¬ (ë°ì´í„° ë¡œë“œ, timestamp ë§¤í•‘, í”¼ì²˜ ê³„ì‚°, ë°ì´í„°ì…‹ ì—…ë°ì´íŠ¸)\n",
    "    for game_id, frame_infos_for_game in game_sample_map.items():\n",
    "        game_feature_dir = os.path.join(cache_dir, game_id)\n",
    "        os.makedirs(game_feature_dir, exist_ok=True)\n",
    "        print(f\"\\n--- Processing Game ID: {game_id} ---\")\n",
    "\n",
    "        tracking_df = pd.read_csv(os.path.join(processed_data_path, game_id, f\"{game_id}_traces.csv\"))\n",
    "        events_df = pd.read_csv(os.path.join(processed_data_path, game_id, f\"{game_id}_merged.csv\"))\n",
    "        teams_df = pd.read_csv(os.path.join(processed_data_path, game_id, f\"{game_id}_teams.csv\"))\n",
    "        events_df[\"time_seconds\"] = pd.to_numeric(events_df[\"time_seconds\"], errors=\"coerce\")\n",
    "\n",
    "        # 2-1. frame_id -> timestamp ë§¤í•‘ (ìŠ¤ì½”í”„ê°€ ì´ ë£¨í”„ ë‚´ë¶€ë¡œ ì œí•œë¨)\n",
    "        frame_id_to_ts = tracking_df.set_index(['period_id', 'frame_id'])['time_seconds'].to_dict() \n",
    "\n",
    "        precomputed_game_features = {} \n",
    "        # 2-2. ì¼ë‹¨ ì „ì²´ì— ëŒ€í•´ ê³„ì‚° ì§„í–‰\n",
    "        for feature_name in feature_list: # ê° í”¼ì²˜ ì´ë¦„ì— ëŒ€í•´\n",
    "            feature_cache_path = os.path.join(game_feature_dir, f\"{feature_name}.npy\") # .npy í™•ì¥ì ì‚¬ìš©\n",
    "            if os.path.exists(feature_cache_path):\n",
    "                with open(feature_cache_path, 'rb') as f:\n",
    "                    feat_result_df = pickle.load(f)\n",
    "            else:\n",
    "                func = getattr(F, feature_name)\n",
    "                game_feature_dir = os.path.join(cache_dir, game_id)\n",
    "                os.makedirs(game_feature_dir, exist_ok=True)\n",
    "                if feature_name == \"sum_pitch_control\":\n",
    "                    feat_result_df  = func(events_df, teams_df)                              \n",
    "                else:\n",
    "                    feat_result_df = func(events_df)  # Series with index=action_id\n",
    "                precomputed_game_features[feature_name] = \\\n",
    "                feat_result_df.set_index('action_id')[feature_name].to_dict()  \n",
    "                with open(feature_cache_path, 'wb') as f:\n",
    "                    pickle.dump(feat_result_df, f)\n",
    "\n",
    "        # 2-3. ìƒ˜í”Œë³„ ê³¼ê±° ì´ë²¤íŠ¸ Bê°œì— ëŒ€í•´ feature ì¶”ì¶œ\n",
    "        for sample_idx, period_id, fid in frame_infos_for_game: \n",
    "            ts = frame_id_to_ts.get((period_id, fid)) \n",
    "            current_sample_data_dict = dataset[sample_idx] \n",
    "            original_feature_tensor = current_sample_data_dict['features'] \n",
    "            B, N, D = original_feature_tensor.shape # BëŠ” ì´ ìƒ˜í”Œì˜ ê³¼ê±° ì´ë²¤íŠ¸ ìˆ˜ (context_length)\n",
    "            past_events = events_df[events_df[\"time_seconds\"] < ts].head(B)\n",
    "            event_ids = past_events[\"action_id\"].tolist()\n",
    "\n",
    "            # ê° featureë³„ë¡œ (B, 1) í…ì„œë¥¼ ìƒì„±í•˜ê³  í•©ì¹˜ê¸°\n",
    "            new_feature_list = []\n",
    "            for feature_name in feature_list:\n",
    "                feat_dict = precomputed_game_features[feature_name]\n",
    "                feat_vals = [feat_dict.get(eid, np.nan) for eid in event_ids]  # (B,)\n",
    "                feat_tensor = torch.tensor(feat_vals, dtype=torch.float32).view(B, 1)  # (B, 1)\n",
    "                expanded = feat_tensor.unsqueeze(1).expand(-1, N, -1)  # (B, N, 1)\n",
    "                new_feature_list.append(expanded)\n",
    "\n",
    "            # ëª¨ë“  feature í†µí•©\n",
    "            new_concat = torch.cat(new_feature_list, dim=-1)  # (B, N, F')\n",
    "            final_feature_tensor = torch.cat([original_feature_tensor, new_concat], dim=-1)\n",
    "            current_sample_data_dict['features'] = final_feature_tensor\n",
    "            dataset[sample_idx] = current_sample_data_dict  # ìµœì¢… ì €ì¥\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd98db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_shape_diff(dataset, dataset_name=\"dataset\"):\n",
    "    print(f\"[{dataset_name}] Feature shape before update:\")\n",
    "    for i in range(3):  # ì•ì˜ 3ê°œ ìƒ˜í”Œë§Œ ì˜ˆì‹œë¡œ í™•ì¸\n",
    "        print(f\"  Sample {i}: {dataset[i]['features'].shape}\")\n",
    "\n",
    "# 1. ì—…ë°ì´íŠ¸ ì „\n",
    "print_feature_shape_diff(train_dataset, \"train_dataset (before)\")\n",
    "print_feature_shape_diff(test_dataset, \"test_dataset (before)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "134fceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Game ID: 153379 ---\n"
     ]
    }
   ],
   "source": [
    "processed_data_path = \"/home/exPress/express-v2/data/bepro/processed\"\n",
    "feature_list = [\n",
    "                'distance_ball_goal',\n",
    "                'distance_ball_sideline', 'distance_ball_goalline', 'actor_speed', 'angle_to_goal', \n",
    "                'elapsed_time','closest_defender_dist', 'closest_defender_speed', 'speed_diff_actor_defender',\n",
    "                'nb_of_3m_radius', 'nb_of_5m_radius','nb_of_10m_radius', 'dist_defender_to_sideline','dist_defender_to_goaline',\n",
    "                'sum_pitch_control'\n",
    "                ]\n",
    "\n",
    "# update_features(train_dataset, feature_list, processed_data_path, cache_dir=\"/home/exPress/express-v2/data/bepro/feature\")\n",
    "update_features(test_dataset, feature_list, processed_data_path, cache_dir=\"/home/exPress/express-v2/data/bepro/feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e018df08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_dataset (before)] Feature shape before update:\n",
      "  Sample 0: torch.Size([4, 23, 19])\n",
      "  Sample 1: torch.Size([4, 23, 19])\n",
      "  Sample 2: torch.Size([2, 23, 19])\n"
     ]
    }
   ],
   "source": [
    "def print_feature_shape_diff(dataset, dataset_name=\"dataset\"):\n",
    "    print(f\"[{dataset_name}] Feature shape before update:\")\n",
    "    for i in range(3):  # ì•ì˜ 3ê°œ ìƒ˜í”Œë§Œ ì˜ˆì‹œë¡œ í™•ì¸\n",
    "        print(f\"  Sample {i}: {dataset[i]['features'].shape}\")\n",
    "\n",
    "# 1. ì—…ë°ì´íŠ¸ ì „\n",
    "# print_feature_shape_diff(train_dataset, \"train_dataset (before)\")\n",
    "print_feature_shape_diff(test_dataset, \"test_dataset (before)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95787556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160    1\n",
       "Name: period_id, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces_df = pd.read_csv('/home/exPress/express-v2/data/bepro/processed/153379/153379_traces.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "582a1b4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 18 is out of bounds for dimension 0 with size 18",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataset)):\n\u001b[32m      9\u001b[39m     sample = train_dataset[i]\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     x_tensor = \u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfeatures\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_features_idx\u001b[49m\u001b[43m]\u001b[49m[-\u001b[32m1\u001b[39m:]\n\u001b[32m     11\u001b[39m     press_intensity = sample[\u001b[33m'\u001b[39m\u001b[33mpressing_intensity\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m:]\n\u001b[32m     12\u001b[39m     y_tensor = sample[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mIndexError\u001b[39m: index 18 is out of bounds for dimension 0 with size 18"
     ]
    }
   ],
   "source": [
    "num_seq = 150\n",
    "num_agents = 11\n",
    "use_pressing_intensity = True\n",
    "selected_features_idx = [i for i in range(19)]\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "for i in range(len(train_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-1:]\n",
    "    press_intensity = sample['pressing_intensity'][-1:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "            \n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    train_features.append(feature_vector)\n",
    "    train_labels.append(y_tensor.item())\n",
    "\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "for i in range(len(test_dataset)):\n",
    "    sample = test_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-1:]\n",
    "    press_intensity = sample['pressing_intensity'][-1:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    \n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    test_features.append(feature_vector)\n",
    "    test_labels.append(y_tensor.item())\n",
    "\n",
    "X_train = np.array(train_features)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = np.array(test_features)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c93e137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 18])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ac95b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Dataset Distribution Summary\n",
      "========================================\n",
      "Train Set:\n",
      "  Total samples: 5922\n",
      "    Label 0:  4361 samples (73.64%)\n",
      "    Label 1:  1561 samples (26.36%)\n",
      "----------------------------------------\n",
      "Validation Set:\n",
      "  Total samples: 1481\n",
      "    Label 0:  1101 samples (74.34%)\n",
      "    Label 1:   380 samples (25.66%)\n",
      "----------------------------------------\n",
      "Test Set:\n",
      "  Total samples: 658\n",
      "    Label 0:   547 samples (83.13%)\n",
      "    Label 1:   111 samples (16.87%)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_dataset_distribution(y_train, y_val, y_test):\n",
    "    def _print_split(name, labels):\n",
    "        total = len(labels)\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        print(f\"{name} Set:\")\n",
    "        print(f\"  Total samples: {total}\")\n",
    "        for label, count in zip(unique, counts):\n",
    "            percent = (count / total) * 100\n",
    "            print(f\"    Label {label}: {count:>5} samples ({percent:5.2f}%)\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    print(\"\\nğŸ“Š Dataset Distribution Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    _print_split(\"Train\", y_train)\n",
    "    _print_split(\"Validation\", y_val)\n",
    "    _print_split(\"Test\", y_test)\n",
    "\n",
    "print_dataset_distribution(y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ff0d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost DMatrix objects for train and test sets\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Set XGBoost training parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # binary classification\n",
    "    'eval_metric': 'auc',            # evaluation metric: AUC\n",
    "    'max_depth': 6,                  # maximum depth of trees\n",
    "    'eta': 0.1,                      # learning rate\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Specify the watchlist to evaluate performance on training and test sets during training\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a3ba1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.76474\teval-auc:0.58872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/expressv2/lib/python3.11/site-packages/xgboost/core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-auc:0.79538\teval-auc:0.60409\n",
      "[2]\ttrain-auc:0.81498\teval-auc:0.63239\n",
      "[3]\ttrain-auc:0.83127\teval-auc:0.64188\n",
      "[4]\ttrain-auc:0.83337\teval-auc:0.64854\n",
      "[5]\ttrain-auc:0.83850\teval-auc:0.65784\n",
      "[6]\ttrain-auc:0.84749\teval-auc:0.65705\n",
      "[7]\ttrain-auc:0.86106\teval-auc:0.66110\n",
      "[8]\ttrain-auc:0.86346\teval-auc:0.66360\n",
      "[9]\ttrain-auc:0.87747\teval-auc:0.66454\n",
      "[10]\ttrain-auc:0.89042\teval-auc:0.66611\n",
      "[11]\ttrain-auc:0.89713\teval-auc:0.66332\n",
      "[12]\ttrain-auc:0.90123\teval-auc:0.66548\n",
      "[13]\ttrain-auc:0.90507\teval-auc:0.66677\n",
      "[14]\ttrain-auc:0.91075\teval-auc:0.66829\n",
      "[15]\ttrain-auc:0.91485\teval-auc:0.66997\n",
      "[16]\ttrain-auc:0.91735\teval-auc:0.67385\n",
      "[17]\ttrain-auc:0.92745\teval-auc:0.67296\n",
      "[18]\ttrain-auc:0.92733\teval-auc:0.67467\n",
      "[19]\ttrain-auc:0.93228\teval-auc:0.67536\n",
      "[20]\ttrain-auc:0.93604\teval-auc:0.67778\n",
      "[21]\ttrain-auc:0.93696\teval-auc:0.67840\n",
      "[22]\ttrain-auc:0.93916\teval-auc:0.67838\n",
      "[23]\ttrain-auc:0.94082\teval-auc:0.67863\n",
      "[24]\ttrain-auc:0.94757\teval-auc:0.67519\n",
      "[25]\ttrain-auc:0.95109\teval-auc:0.67647\n",
      "[26]\ttrain-auc:0.95353\teval-auc:0.67524\n",
      "[27]\ttrain-auc:0.95810\teval-auc:0.67672\n",
      "[28]\ttrain-auc:0.96083\teval-auc:0.67652\n",
      "[29]\ttrain-auc:0.96151\teval-auc:0.67753\n",
      "[30]\ttrain-auc:0.96406\teval-auc:0.67887\n",
      "[31]\ttrain-auc:0.96710\teval-auc:0.67812\n",
      "[32]\ttrain-auc:0.97031\teval-auc:0.67754\n",
      "[33]\ttrain-auc:0.97128\teval-auc:0.67982\n",
      "[34]\ttrain-auc:0.97284\teval-auc:0.67946\n",
      "[35]\ttrain-auc:0.97418\teval-auc:0.67962\n",
      "[36]\ttrain-auc:0.97518\teval-auc:0.68058\n",
      "[37]\ttrain-auc:0.97701\teval-auc:0.68148\n",
      "[38]\ttrain-auc:0.97859\teval-auc:0.68201\n",
      "[39]\ttrain-auc:0.98021\teval-auc:0.68088\n",
      "[40]\ttrain-auc:0.98128\teval-auc:0.68154\n",
      "[41]\ttrain-auc:0.98277\teval-auc:0.68053\n",
      "[42]\ttrain-auc:0.98422\teval-auc:0.67998\n",
      "[43]\ttrain-auc:0.98527\teval-auc:0.67974\n",
      "[44]\ttrain-auc:0.98587\teval-auc:0.67973\n",
      "[45]\ttrain-auc:0.98681\teval-auc:0.68114\n",
      "[46]\ttrain-auc:0.98764\teval-auc:0.68151\n",
      "[47]\ttrain-auc:0.98834\teval-auc:0.68375\n",
      "[48]\ttrain-auc:0.98890\teval-auc:0.68402\n",
      "[49]\ttrain-auc:0.98983\teval-auc:0.68471\n",
      "[50]\ttrain-auc:0.99032\teval-auc:0.68526\n",
      "[51]\ttrain-auc:0.99082\teval-auc:0.68482\n",
      "[52]\ttrain-auc:0.99127\teval-auc:0.68551\n",
      "[53]\ttrain-auc:0.99189\teval-auc:0.68623\n",
      "[54]\ttrain-auc:0.99201\teval-auc:0.68613\n",
      "[55]\ttrain-auc:0.99240\teval-auc:0.68458\n",
      "[56]\ttrain-auc:0.99265\teval-auc:0.68417\n",
      "[57]\ttrain-auc:0.99343\teval-auc:0.68463\n",
      "[58]\ttrain-auc:0.99384\teval-auc:0.68426\n",
      "[59]\ttrain-auc:0.99449\teval-auc:0.68374\n",
      "[60]\ttrain-auc:0.99471\teval-auc:0.68289\n",
      "[61]\ttrain-auc:0.99510\teval-auc:0.68380\n",
      "[62]\ttrain-auc:0.99569\teval-auc:0.68420\n",
      "[63]\ttrain-auc:0.99620\teval-auc:0.68456\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(params, dtrain, num_rounds, watchlist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03cccea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7353\n",
      "Test AUC: 0.6846\n"
     ]
    }
   ],
   "source": [
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bc7c6",
   "metadata": {},
   "source": [
    "# 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff7bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seq = 150\n",
    "num_agents = 11\n",
    "use_pressing_intensity = False\n",
    "selected_features_idx = [1, 2, 4, 7]\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "for i in range(len(train_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-90:]\n",
    "    press_intensity = sample['pressing_intensity'][-90:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "            \n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    train_features.append(feature_vector)\n",
    "    train_labels.append(y_tensor.item())\n",
    "\n",
    "\n",
    "test_features = []\n",
    "test_labels = []\n",
    "for i in range(len(test_dataset)):\n",
    "    sample = test_dataset[i]\n",
    "    x_tensor = sample['features'][..., selected_features_idx][-90:]\n",
    "    press_intensity = sample['pressing_intensity'][-90:]\n",
    "    y_tensor = sample['label']\n",
    "    \n",
    "    # Flatten the sequence data: shape (sequence_length, num_features) -> (sequence_length*num_features,)\n",
    "    feature_vector = x_tensor.flatten().numpy()\n",
    "    \n",
    "    if use_pressing_intensity:\n",
    "        if press_intensity.shape[1] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], num_agents-press_intensity.shape[1], press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=1)\n",
    "        if press_intensity.shape[2] != num_agents:\n",
    "            pad_tensor = torch.zeros(press_intensity.shape[0], press_intensity.shape[1], num_agents-press_intensity.shape[2])\n",
    "            press_intensity = torch.cat([press_intensity, pad_tensor], dim=2)\n",
    "        \n",
    "        press_vector = press_intensity.flatten().numpy()\n",
    "        # Concatenate the flattened sequence data with the pressing intensity\n",
    "        feature_vector = np.concatenate((feature_vector, press_vector))\n",
    "    test_features.append(feature_vector)\n",
    "    test_labels.append(y_tensor.item())\n",
    "\n",
    "X_train = np.array(train_features)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test = np.array(test_features)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b82432f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Dataset Distribution Summary\n",
      "========================================\n",
      "Train Set:\n",
      "  Total samples: 11392\n",
      "    Label 0:  9138 samples (80.21%)\n",
      "    Label 1:  2254 samples (19.79%)\n",
      "----------------------------------------\n",
      "Validation Set:\n",
      "  Total samples: 2849\n",
      "    Label 0:  2281 samples (80.06%)\n",
      "    Label 1:   568 samples (19.94%)\n",
      "----------------------------------------\n",
      "Test Set:\n",
      "  Total samples: 1721\n",
      "    Label 0:  1358 samples (78.91%)\n",
      "    Label 1:   363 samples (21.09%)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_dataset_distribution(y_train, y_val, y_test):\n",
    "    def _print_split(name, labels):\n",
    "        total = len(labels)\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        print(f\"{name} Set:\")\n",
    "        print(f\"  Total samples: {total}\")\n",
    "        for label, count in zip(unique, counts):\n",
    "            percent = (count / total) * 100\n",
    "            print(f\"    Label {label}: {count:>5} samples ({percent:5.2f}%)\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    print(\"\\nğŸ“Š Dataset Distribution Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    _print_split(\"Train\", y_train)\n",
    "    _print_split(\"Validation\", y_val)\n",
    "    _print_split(\"Test\", y_test)\n",
    "\n",
    "print_dataset_distribution(y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e48d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost DMatrix objects for train and test sets\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Set XGBoost training parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # binary classification\n",
    "    'eval_metric': 'auc',            # evaluation metric: AUC\n",
    "    'max_depth': 6,                  # maximum depth of trees\n",
    "    'eta': 0.1,                      # learning rate\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Specify the watchlist to evaluate performance on training and test sets during training\n",
    "watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "num_rounds = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "856ef086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/miniconda/envs/mhl_py311/lib/python3.11/site-packages/xgboost/core.py:726: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.72404\teval-auc:0.59755\n",
      "[1]\ttrain-auc:0.77449\teval-auc:0.61684\n",
      "[2]\ttrain-auc:0.80143\teval-auc:0.61842\n",
      "[3]\ttrain-auc:0.82563\teval-auc:0.62081\n",
      "[4]\ttrain-auc:0.83993\teval-auc:0.62739\n",
      "[5]\ttrain-auc:0.85611\teval-auc:0.63009\n",
      "[6]\ttrain-auc:0.86313\teval-auc:0.63397\n",
      "[7]\ttrain-auc:0.87409\teval-auc:0.63416\n",
      "[8]\ttrain-auc:0.88935\teval-auc:0.63792\n",
      "[9]\ttrain-auc:0.89944\teval-auc:0.63648\n",
      "[10]\ttrain-auc:0.90767\teval-auc:0.63826\n",
      "[11]\ttrain-auc:0.91626\teval-auc:0.63678\n",
      "[12]\ttrain-auc:0.92196\teval-auc:0.63293\n",
      "[13]\ttrain-auc:0.92891\teval-auc:0.63344\n",
      "[14]\ttrain-auc:0.93481\teval-auc:0.63360\n",
      "[15]\ttrain-auc:0.93753\teval-auc:0.63349\n",
      "[16]\ttrain-auc:0.94254\teval-auc:0.63322\n",
      "[17]\ttrain-auc:0.94739\teval-auc:0.63347\n",
      "[18]\ttrain-auc:0.94938\teval-auc:0.63573\n",
      "[19]\ttrain-auc:0.95371\teval-auc:0.63360\n",
      "[20]\ttrain-auc:0.95596\teval-auc:0.63550\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost model with early stopping on the evaluation set\n",
    "bst = xgb.train(params, dtrain, num_rounds, watchlist, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96af079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8027\n",
      "Test AUC: 0.6491\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c5df0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7989\n",
      "Test AUC: 0.6465\n"
     ]
    }
   ],
   "source": [
    "# W/O Pressing Intensity\n",
    "# Get predictions on the test set\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_label)\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Test AUC: {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb1665e",
   "metadata": {},
   "source": [
    "# 2. SoccerMap / exPress Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96d976f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import os\n",
    "os.chdir('/home/work/MHL/express-v2')\n",
    "import argparse # To accept checkpoint path as argument\n",
    "\n",
    "# Import project modules\n",
    "# import config  # Import static configurations\n",
    "from model import PytorchSoccerMapModel # Import Lightning model\n",
    "from datasets import PressingSequenceDataset, SoccerMapInputDataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08a1fab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from /data/MHL/pressing-intensity/test_dataset.pkl...\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42, workers=True) # Ensure reproducibility\n",
    "\n",
    "DATA_PATH = \"/data/MHL/pressing-intensity\" # Path where pickled datasets are saved\n",
    "test_dataset = SoccerMapInputDataset(os.path.join(DATA_PATH, \"test_dataset.pkl\"))\n",
    "\n",
    "if len(test_dataset) == 0:\n",
    "    print(\"Loaded test dataset is empty. Exiting.\")\n",
    "\n",
    "# Custom collate function to handle potential None values from dataset errors\n",
    "def collate_fn_skip_none(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    if not batch: return None\n",
    "    try: return torch.utils.data.dataloader.default_collate(batch)\n",
    "    except RuntimeError: return None # Skip batch if collation error\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    # collate_fn=collate_fn_skip_none\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45aabfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Train a pressing evaluation model.\")\n",
    "# parser.add_argument(\"--model_type\", type=str, default=\"soccermap\", choices=['soccermap', 'xgboost', 'exPress'], help=\"Path to the model checkpoint (.ckpt) file saved during training.\")\n",
    "# parser.add_argument(\"--root_path\", type=str, default=\"/data/MHL/pressing-intensity\", help=\"Path to the data file.\")\n",
    "parser.add_argument(\"--model_type\", type=str, default=\"soccermap\", choices=['soccermap', 'xgboost', 'exPress'], help=\"Path to the model checkpoint (.ckpt) file saved during training.\")\n",
    "parser.add_argument(\"--root_path\", type=str, default=\"/data/MHL/pressing-intensity\", help=\"Path to the data file.\")\n",
    "parser.add_argument(\"--mode\", type=str, default=\"train\", choices=['train', 'test'], help=\"Mode: 'train' or 'test'.\")\n",
    "parser.add_argument(\"--ckpt_path\", type=str, default=None, help=\"Path to checkpoint file (Required for 'test' mode).\")\n",
    "parser.add_argument(\"--params_path\", type=str, default=\"params.json\", help=\"Path to the JSON containing configurations.\")\n",
    "parser.add_argument(\"--seed\", type=int, default=42, help=\"Seed number.\")\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "args.mode = 'test'\n",
    "args.model_type = \"exPress\"\n",
    "args.ckpt_path = \"/data/MHL/pressing-intensity/checkpoints/exPress-epoch=28-val_loss=0.49.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4dcd43e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations loaded from params.json.\n"
     ]
    }
   ],
   "source": [
    "from components import press\n",
    "\n",
    "\n",
    "component_dict = {\n",
    "                    \"soccermap\": press.SoccerMapComponent,\n",
    "                    \"exPress\": press.exPressComponent,\n",
    "                }\n",
    "\n",
    "exp = component_dict[args.model_type](args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193af97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expressv2",
   "language": "python",
   "name": "expressv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
